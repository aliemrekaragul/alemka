results$conv_part_3 <- (results$total_part_3 * max_score_part3) / part3
results$conv_part_4 <- (results$total_part_4 * max_score_part4) / part4
# requested_output 6: 3/3
sumstats <- rbind(
summary(results$conv_part_1),
summary(results$conv_part_2),
summary(results$conv_part_3),
summary(results$conv_part_4)
)
rownames(sumstats) <- c("Part-1:", "Part-2:", "Part-3:", "Part-4:")
}
#requested_output 1 :EXAM TAKER REPORT:
exam_results <- as.data.frame(cbind(
data$st_id,
data$st_name,
data$st_surname,
data$section,
respo,
results
))
if (part4 == 1 & part3 != 1) {
st_resp_itemnames <-
paste0("st_resp@item", 1:(part1 + part2 + part3 ))
dicho_itemnames <- paste0("item", 1:(part1 + part2 + part3 ))
colnames(exam_results) <-
c(
"st_id",
"st_name",
"st_fam.name",
"section",
st_resp_itemnames,
dicho_itemnames,
"Truescore@part1",
"Truescore@part2",
"Truescore@part3",
"conv_sco@part1",
"conv_sco@part2",
"conv_sco@part3"
)
}else if(part3 == 1 & part4 == 1){
st_resp_itemnames <-
paste0("st_resp@item", 1:(part1 + part2))
dicho_itemnames <- paste0("item", 1:(part1 + part2))
colnames(exam_results) <-
c(
"st_id",
"st_name",
"st_fam.name",
"section",
st_resp_itemnames,
dicho_itemnames,
"Truescore@part1",
"Truescore@part2",
"conv_sco@part1",
"conv_sco@part2"
)
}else{
st_resp_itemnames <-
paste0("st_resp@item", 1:(part1 + part2 + part3 + part4))
dicho_itemnames <- paste0("item", 1:(part1 + part2 + part3 + part4))
colnames(exam_results) <-
c(
"st_id",
"st_name",
"st_fam.name",
"section",
st_resp_itemnames,
dicho_itemnames,
"Truescore@part1",
"Truescore@part2",
"Truescore@part3",
"Truescore@part4",
"conv_sco@part1",
"conv_sco@part2",
"conv_sco@part3",
"conv_sco@part4"
)
}
#requested_output 2: ITEM LEVEL ANALYSIS:
scored_respo<-scored_respo[ rowSums(scored_respo[,-1]) > 0, ]
#item_stats<- ItemAnalysis(scored_respo)
difficulties<-round(colMeans(scored_respo),2)
discriminations<-round(item.total(scored_respo)$Item.Total,2)
disc.Labels<-labelDiscriminations(discriminations)
diff.Labels<-labelDifficulties(difficulties)
item_stats<- cbind(difficulties, discriminations, disc.Labels,diff.Labels )
colnames(item_stats)<- c("difficulty index", "discrimination index", "difficulty comment", "discrimination comment")
#requested_output 7:TEST LEVEL ANALYSIS:
mytable<-table( diff.Labels, disc.Labels)
#requested_output 3:TEST LEVEL ANALYSIS:
#güvenirlik katsatısı
alpha_index<-cronbach.alpha(scored_respo)
#requested_output 4:OPTION LEVEL ANALYSIS:
if (p_table=="Counts"){p_table<-FALSE } else{ p_table<-TRUE}
option_level_stats <- ShinyItemAnalysis::DistractorAnalysis(data_for_distractorAnal,
ans_for_distractorAnal,
p.table  = p_table, num.groups=3)
if(requested_output == 1){ return(exam_results)}
if(requested_output == 2){ return(item_stats)}
if(requested_output == 3){ return(alpha_index)}
if(requested_output == 4){ return(option_level_stats )}
if(requested_output == 5){ return(as.data.frame(scored_respo))}
if(requested_output == 6){ return(as.data.frame(sumstats))}
if(requested_output == 7){ return(mytable)}
}
labelDifficulties<-function (itemDifficulties){
difficultycommemnt <- c()
for (difficulty in 1:length(itemDifficulties)){
if(itemDifficulties[difficulty] <= 0.2){difficultycommemnt[difficulty]<- "difficult"
}else if(itemDifficulties[difficulty] > 0.2 & itemDifficulties[difficulty] < 0.8){difficultycommemnt[difficulty]<- "moderate"
}else{difficultycommemnt[difficulty]<- "easy"
}
}
return(difficultycommemnt)
}
labelDiscriminations<- function(itemDiscriminations){
discriminationcomment<-c()
for (discrimination in 1:length(itemDiscriminations)) {
if(itemDiscriminations[discrimination] <= 0 | is.na(itemDiscriminations[discrimination] )  ){discriminationcomment[discrimination]<- "DISCARD"
}else if(itemDiscriminations[discrimination] <= 0.2 & itemDiscriminations[discrimination] > 0){ discriminationcomment[discrimination]<- "revise"
}else if(itemDiscriminations[discrimination] <= 0.3 & itemDiscriminations[discrimination] > 0.2){ discriminationcomment[discrimination]<- "mediocre"
}else if(itemDiscriminations[discrimination] <= 0.4 & itemDiscriminations[discrimination] > 0.3){ discriminationcomment[discrimination]<- "good"
}else if(itemDiscriminations[discrimination] > 0.4){ discriminationcomment[discrimination]<- "very good"
}
}
return(discriminationcomment)
}
asd1<-main_function("sample.dat", 10, 10, 10, 10, 100, 100, 100, 100, "Counts", 1)
asd1<-main_function("sample.dat", 10, 10, 10, 0, 100, 100, 100, 0, "Counts", 1)
asd1<-main_function("sample.dat", 10, 10, 10, 0, 100, 100, 100, 0, "Counts", 1)
runApp()
quarto install extension schochastics/quarto-social-share
>>>>>>> parent of 713d634 (google-fit)
library(rvest)
library(dplyr)
html           <- read_html("https://eksisozluk.com/veri-bilimi--3426406")
#get all the links in a page
links          <- html %>% html_nodes("a.url")  %>%  html_attr("href")
#get the number of pages of a title
n_of_pages     <- html %>% html_nodes(".pager")  %>%  html_attr("data-pagecount") %>% as.numeric()
n_of_pages[1]
#get all the entries in a page
entries        <- html %>% html_nodes(".content") %>%html_text()
entries
links
knitr::opts_chunk$set(echo = FALSE)
#| warning: false
#| eval: true
#| echo: true
#| code-fold: false
links <- html %>% html_nodes("a.url")  %>%  html_attr("href")
links
#| warning: false
#| eval: true
#| echo: true
#| code-fold: false
entries        <- html %>% html_nodes(".content") %>%html_text()
entries
library(wordcloud)
install.packages("tm")
library(tm)
library(wordcloud)
?stopwords()
entries <- entries %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
?tm_map()
entries<-Corpus(VectorSource(entries))
entries <- entries %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
entries <- tm_map(entries, content_transformer(tolower))
entries <- tm_map(entries, removeWords)
entries
View(entries)
entries[["1"]][["content"]]
dtm <- TermDocumentMatrix(entries)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix),decreasing=TRUE)
df <- data.frame(word = names(words),freq=words)
wordcloud(words = df$word, freq = df$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
#get all the links in a page
links          <- html %>% html_nodes("a.url")  %>%  html_attr("href")
links
#get the number of pages of a title
n_of_pages<- html %>% html_nodes(".pager")  %>%  html_attr("data-pagecount") %>% as.numeric()
n_of_pages[1]
#get all the entries in a page
entries  <- html %>% html_nodes(".content") %>%html_text()
entries
head(entries)
?head()
head(entries, 2)
head(entries, 3)
wordcloud(words = entries, freq = df$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
##WORD CLOUD
entries<-Corpus(VectorSource(entries))
entries <- entries %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
entries <- tm_map(entries, content_transformer(tolower))
entries <- tm_map(entries, removeWords)
term_matrix <- as.matrix(TermDocumentMatrix(entries) )
View(term_matrix)
words <- sort(rowSums(term_matrix),decreasing=TRUE)
df <- data.frame(word = names(words),freq=words)
View(df)
#get all the links in a page
links          <- html %>% html_nodes("a.url")  %>%  html_attr("href")
links
#get the number of pages of a title
n_of_pages<- html %>% html_nodes(".pager")  %>%  html_attr("data-pagecount") %>% as.numeric()
n_of_pages[1]
#get all the entries in a page
entries  <- html %>% html_nodes(".content") %>%html_text()
entries
head(entries, 3)
##WORD CLOUD
entries<-Corpus(VectorSource(entries))
entries <- entries %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
entries <- tm_map(entries, content_transformer(tolower))
entries <- tm_map(entries, removeWords)
term_matrix <- as.matrix(TermDocumentMatrix(entries) )
#words <- sort(rowSums(term_matrix),decreasing=TRUE)
word_freqs <- data.frame(word = names(term_matrix ),freq=words)
wordcloud(words = df$word, freq = df$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = df$word, freq = df$freq, min.freq = 2,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark"))
wordcloud(words = df$word, freq = df$freq, min.freq = 2,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark1"))
wordcloud(words = df$word, freq = df$freq, min.freq = 2,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = word_freqs$word, freq = word_freqs$freq, min.freq = 2,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
#words <- sort(rowSums(term_matrix),decreasing=TRUE)
word_freqs <- data.frame(word = names(term_matrix ),freq=words)
#get all the entries in a page
entries  <- html %>% html_nodes(".content") %>%html_text()
entries
head(entries, 3)
##WORD CLOUD
entries<-Corpus(VectorSource(entries))
entries <- entries %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
entries <- tm_map(entries, content_transformer(tolower))
entries <- tm_map(entries, removeWords)
term_matrix <- as.matrix(TermDocumentMatrix(entries) )
#words <- sort(rowSums(term_matrix),decreasing=TRUE)
word_freqs <- data.frame(word = names(term_matrix ),freq=words)
word_freqs
term_matrix
View(term_matrix)
term_matrix <- sort(rowSums(term_matrix),decreasing=TRUE)
term_matrix[["bir"]]
word_freqs <- sort(rowSums(term_matrix),decreasing=TRUE)
term_matrix <- as.matrix(TermDocumentMatrix(entries) )
word_freqs <- sort(rowSums(term_matrix),decreasing=TRUE)
word_freqs <- data.frame(word = names(term_matrix ),freq=words)
#get all the entries in a page
entries  <- html %>% html_nodes(".content") %>%html_text()
##WORD CLOUD
entries<-Corpus(VectorSource(entries))
entries <- entries %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
entries <- tm_map(entries, content_transformer(tolower))
entries <- tm_map(entries, removeWords)
term_matrix <- as.matrix(TermDocumentMatrix(entries) )
word_freqs <- sort(rowSums(term_matrix),decreasing=TRUE)
word_freqs <- data.frame(word = names(term_matrix ),freq=words)
word_freqs <- sort(rowSums(term_matrix),decreasing=TRUE)
word_freqs <- data.frame(word = names(word_freqs ),freq=words)
wordcloud(words = word_freqs$word, freq = word_freqs$freq, min.freq = 2,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = word_freqs$word, freq = word_freqs$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
#| warning: false
#| eval: true
#| echo: true
#| code-fold: false
entries        <- html %>% html_nodes(".content") %>%html_text()
#Let's see the first three entries:
head(entries, 3)
#| warning: false
#| eval: true
#| echo: true
#| code-fold: false
#turn entries into corpus
entries<-Corpus(VectorSource(entries))
#apply several functions such as remove punctuation or numbers etc.
entries <- entries %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
entries <- tm_map(entries, content_transformer(tolower))
entries <- tm_map(entries, removeWords)
#| warning: false
#| eval: true
#| echo: true
#| code-fold: false
library(rvest)
library(dplyr)
library(wordcloud)
library(tm)
knitr::opts_chunk$set(echo = FALSE)
#| warning: false
#| eval: true
#| echo: true
#| code-fold: false
library(rvest)
library(dplyr)
library(wordcloud)
library(tm)
#| warning: false
#| eval: true
#| echo: true
#| code-fold: false
html <- read_html("https://eksisozluk.com/veri-bilimi--3426406")
#| warning: false
#| eval: true
#| echo: true
#| code-fold: false
links <- html %>% html_nodes("a.url")  %>%  html_attr("href")
links
#| warning: false
#| eval: true
#| echo: true
#| code-fold: false
entries        <- html %>% html_nodes(".content") %>%html_text()
#Let's see the first three entries:
head(entries, 3)
#| warning: false
#| eval: true
#| echo: true
#| code-fold: false
#turn entries into corpus
entries<-Corpus(VectorSource(entries))
#apply several functions such as remove punctuation or numbers etc.
entries <- entries %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
entries <- tm_map(entries, content_transformer(tolower))
entries <- tm_map(entries, removeWords)
wordcloud(words = word_freqs$word, freq = word_freqs$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
#| warning: false
#| eval: true
#| echo: true
#| code-fold: false
library(wordcloud)
#turn entries into corpus
entries<-Corpus(VectorSource(entries))
#apply several functions such as remove punctuation or numbers etc.
entries <- entries %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
entries <- tm_map(entries, content_transformer(tolower))
entries <- tm_map(entries, removeWords)
knitr::opts_chunk$set(echo = FALSE)
#| warning: false
#| eval: true
#| echo: true
#| code-fold: false
library(rvest)
library(dplyr)
library(wordcloud)
library(tm)
#| warning: false
#| eval: true
#| echo: true
#| code-fold: false
html <- read_html("https://eksisozluk.com/veri-bilimi--3426406")
#| warning: false
#| eval: true
#| echo: true
#| code-fold: false
links <- html %>% html_nodes("a.url")  %>%  html_attr("href")
links
#| warning: false
#| eval: true
#| echo: true
#| code-fold: false
entries        <- html %>% html_nodes(".content") %>%html_text()
#Let's see the first three entries:
head(entries, 3)
#| warning: false
#| eval: true
#| echo: true
#| code-fold: false
library(wordcloud)
#turn entries into corpus
entries<-Corpus(VectorSource(entries))
#apply several functions such as remove punctuation or numbers etc.
entries <- entries %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
entries <- tm_map(entries, content_transformer(tolower))
entries <- tm_map(entries, removeWords)
#| warning: false
#| eval: true
#| echo: true
#| code-fold: false
library(wordcloud)
library(tm)
#turn entries into corpus
entries<-Corpus(VectorSource(entries))
#apply several functions such as remove punctuation or numbers etc.
entries <- entries %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
entries <- tm_map(entries, content_transformer(tolower))
entries <- tm_map(entries, removeWords)
html <- read_html("https://eksisozluk.com/veri-bilimi--3426406")
#get all the links in a page
links          <- html %>% html_nodes("a.url")  %>%  html_attr("href")
links
#get the number of pages of a title
n_of_pages<- html %>% html_nodes(".pager")  %>%  html_attr("data-pagecount") %>% as.numeric()
n_of_pages[1]
#get all the entries in a page
entries  <- html %>% html_nodes(".content") %>%html_text()
entries
head(entries, 3)
##WORD CLOUD
entries<-Corpus(VectorSource(entries))
entries <- entries %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
entries <- tm_map(entries, content_transformer(tolower))
entries <- tm_map(entries, removeWords)
tm_map
?tm_map
entries <- tm_map(entries, content_transformer(tolower))
term_matrix <- as.matrix(TermDocumentMatrix(entries) )
word_freqs <- sort(rowSums(term_matrix),decreasing=TRUE)
word_freqs <- data.frame(word = names(word_freqs ),freq=words)
wordcloud(words = word_freqs$word, freq = word_freqs$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
word_freqs <- data.frame(word=names(word_freqs),freq=words)
names(word_freqs)
word_freqs <- data.frame(word=names(word_freqs),freq=words)
word_freqs
word_freqs <- data.frame(word=names(word_freqs),freq=word_freqs )
wordcloud(words = word_freqs$word, freq = word_freqs$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
#| warning: false
#| eval: true
#| echo: true
#| code-fold: false
library(wordcloud)
library(tm)
#turn entries into corpus
entries<-Corpus(VectorSource(entries))
#apply several functions such as remove punctuation or numbers etc.
entries <- entries %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
entries <- tm_map(entries, content_transformer(tolower))
entries <- tm_map(entries, removeWords)
#| warning: false
#| eval: true
#| echo: true
#| code-fold: false
library(wordcloud)
library(tm)
#turn entries into corpus
entries<-Corpus(VectorSource(entries))
#apply several functions such as remove punctuation or numbers etc.
entries <- entries %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
entries <- tm_map(entries, content_transformer(tolower))
#turn into a matrix
term_matrix <- as.matrix(TermDocumentMatrix(entries) )
#frequency table:
word_freqs <- sort(rowSums(term_matrix),decreasing=TRUE)
word_freqs <- data.frame(word=names(word_freqs),freq=word_freqs )
## word cloud:
wordcloud(words = word_freqs$word, freq = word_freqs$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
