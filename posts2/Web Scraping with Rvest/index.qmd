---
title: "[under development] Web scraping with Rvest package"
#preview: images/paste-A04B6DB6.png
description: |
  "Rvest" is a package for web scraping and harvesting which is developed by Hadley Wickham. He states that he was inspired by python libraries such as "beautiful soup" and "RoboBrowser".
author:
  - name: Ali Emre Karagül
    orcid: 0000-0002-5820-8643
    email: aliemrekaragul@gmail.com
    affiliations:
      - name: TOBB ETU- University of Economics & Technology
date: 2023-01-06
categories: [Rvest, Wordcloud, Data-viz]
image: "image.png"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Introduction

In this post, we will delve into harvesting a web page, [Ekşi Sözlük](https://eksisozluk.com/). This process won't include the automation of the process. Ekşi Sözlük is a reddit-like web site where users share their ideas on certain topics. Our target topic is "veri bilimi" (a.k.a. data science in English).

The R packages that we use in this post are as follows:

```{r eval=TRUE, echo=FALSE, code_folding=FALSE}
#| warning: false
#| eval: true
#| echo: true
#| code-fold: false
library(rvest)
library(dplyr)
library(wordcloud)
library(tm)
```

## Processing

First things first; we start by introducing the webpage that we want to harvest.

```{r}
#| warning: false
#| eval: true
#| echo: true
#| code-fold: false
html <- read_html("https://eksisozluk.com/veri-bilimi--3426406")
```

Rvest allos us to collect any type of HTML tag from the current page. Let's suppose we would like to collect all the links in a topic page:

```{r}
#| warning: false
#| eval: true
#| echo: true
#| code-fold: false

links <- html %>% html_nodes("a.url")  %>%  html_attr("href")
links
```

Or maybe we would like to collect all the entries on the given page:

```{r}
#| warning: false
#| eval: true
#| echo: true
#| code-fold: false
entries        <- html %>% html_nodes(".content") %>%html_text()    

#Let's see the first three entries:
head(entries, 3)
```

Now that you have all the entries in a page, it is easy to carry out a text analysis with it. Let's simply create a word cloud:

```{r}
#| warning: false
#| eval: true
#| echo: true
#| code-fold: false
#| 
#turn entries into corpus

entries<-Corpus(VectorSource(entries))

#apply several functions such as remove punctuation or numbers etc.

entries <- entries %>%
  tm_map(removeNumbers) %>%
  tm_map(removePunctuation) %>%
  tm_map(stripWhitespace)
entries <- tm_map(entries, content_transformer(tolower))

#turn into a matrix
term_matrix <- as.matrix(TermDocumentMatrix(entries) )

#frequency table:
word_freqs <- sort(rowSums(term_matrix),decreasing=TRUE) 
word_freqs <- data.frame(word=names(word_freqs),freq=word_freqs )

## word cloud:
wordcloud(words = word_freqs$word, freq = word_freqs$freq, min.freq = 1,          
          max.words=200, random.order=FALSE, rot.per=0.35,            
          colors=brewer.pal(8, "Dark2"))
```

## Conclusion

This post is not complete, yet will be completed soon.
