{
  "hash": "2f89bde0d5aa30e8bc292e6442c58300",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Automated Essay Scoring (AES) with R\"\ndescription: |\n  At the core of Automated Essay Scoring (AES) is natural language processing (NLP) and machine learning. These systems are designed to analyze the text based on a set of predefined criteria, which may include factors such as grammar, sentence structure, vocabulary, coherence, and argumentative quality. The algorithms look for patterns and features in the text, such as the presence of thesis statements, use of evidence, and logical progression of ideas. This data is then used to generate a score that reflects the essay's overall quality. In this blog post, we will explore the basics of NLP and AES with a prominent dataset: Automated Student Assessment Prize (ASAP) dataset sponsored by Hewlett. \nauthor:\n  - name: Ali Emre Karag√ºl\n    orcid: 0000-0002-5820-8643\n    email: aliemrekaragul@gmail.com\n    affiliations:\n      - name: TOBB ETU- University of Economics & Technology\ndate: 2023-10-23\ncategories: [\n  readxl,textstem,stopwords,stringr,quanteda,tm,tidyverse,\n  NLP, AES, \n  machine learning, regression, classification\n  ]\nimage: \"image.png\"\noutput:\n    self_contained: true\n    code_folding: false\n---\n\n\n## Introduction\n\nIn the realm of education and standardized testing, technological advancements have brought forth a significant transformation. Among the noteworthy innovations in this field is the adoption of Automated Essay Scoring (AES), an approach that leverages the capabilities of natural language processing (NLP) and machine learning. AES holds the potential to redefine the essay evaluation and grading process, offering efficiency, consistency, and accessibility in a way previously unattainable.\n\nAt its essence, AES relies on sophisticated algorithms to examine written text, subjecting it to a predefined set of criteria. These criteria encompass various aspects, including grammar, sentence structure, vocabulary, coherence, and the quality of argumentation. In this regard, AES algorithms function akin to meticulous digital assessors, diligently seeking out patterns and features within the text. They assess elements such as the presence of persuasive thesis statements, the adept use of supporting evidence, and the logical flow of ideas within the essay. The result of this is a numerical score that reflects the overall quality of the essay in question.\n\nToday we will develop a linear regression model to predict essay scores using the famous ASAP dataset. There are eight different essay types in this dataset to explore. Here we will use the essay set 2. Before you continue, please go and read the description and the details [on Kaggle.](https://www.kaggle.com/competitions/asap-aes/data) As we will use only one essay set, I have preapared the data as a separate csv file and if you are already familiar with the ASAP data (or you have taken a look at the Kaggle page), please download the data for our use case from [here](https://docs.google.com/spreadsheets/d/1xi-k1cJGADOgtp85sfJ4ZBr1P-YREhx_/edit?usp=sharing&ouid=109837621769671436242&rtpof=true&sd=true). The packages and some of their functions that we will be using in this topic are:\n\n\n::: {.cell code_folding='false' filename='Requirements'}\n\n```{.r .cell-code  code-fold=\"false\"}\nlibrary(\"rmarkdown\") \n# paged_table() \nlibrary(\"readxl\") \n# read_excel()\nlibrary(\"tidyverse\") \nlibrary(\"textstem\") \n# lemmatize_strings()\nlibrary(\"stopwords\") \n# stopwords()\nlibrary(\"stringr\")   \n# str_squish()\nlibrary(\"tm\")        \n# remove_words()\nlibrary(\"quanteda\")  \n# nsentence() \n```\n:::\n\n\n## 1. Preprocessing\n\nNow that you have downloaded the data, move it to your working directory and follow along while reading. Let's load the data and see the head of them:\n\n\n::: {.cell code_folding='false' filename=''}\n\n```{.r .cell-code  code-fold=\"false\"}\nessay_set_2 <- read_excel(\"essay_set_2.xlsx\") \npaged_table(head(essay_set_2, 2)) # paged_table() function is for a beautified table view on this page. You don't need to use it on your own trial.\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"essay_id\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"essay_set\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"essay\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"rater1_domain1\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"rater2_domain1\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"domain1_score\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"rater1_domain2\"],\"name\":[7],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"rater2_domain2\"],\"name\":[8],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"domain2_score\"],\"name\":[9],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"2978\",\"2\":\"2\",\"3\":\"Certain materials being removed from libraries such as books, music and magazines, shouldn't be removed from the libraries. It gives people a chance to understand how the real world @CAPS2.     Having certain materials such as books and music definitly should not be removed, because most books and music can show most people how bad the statement in the book @CAPS2 or how bad the lyrics are in a song, and help that person to avoid that type of thing that the book or song @CAPS2 saying to the reader or listener. People should give every type of music at least a try and not always doubt what they hear about what people say about that type of music. I always hear about people saying how bad the band @PERSON1 A.M. @CAPS2, just because in the lyrics it talks about drugs and how much cursing each song has. Really the band @CAPS2 talking about one mans life and how he turns his life from being a drug addict to having the best life someone could ever live. People always doubted him and never gave his music a chance. Another example would be @PERSON1's book, '@CAPS1 @CAPS2 @CAPS3 @CAPS4' for it talks about drug addicts, homeless people, people who have been born with disfigured arms or even someone who lost there legs, and telling how beautiful each and everyone of them really are. His book taught me a few things and made me think different about people. It doesn't matter how they look or how they talk, no matter what, that person @CAPS2 beautiful.     As far as movies and magazines has gone within the last few years, I think that the also shouldn't be taken from libraries. I think @CAPS1 for the same reason of how I feel about the books and music. Of course we see previews of movies and think that they @MONTH1 not be good, but libraries shouldn't keep leave them out. Movies @CAPS2 a great way to learn how to treat others and how to act around other people when you don't know how to act. If you act differently around people that you've never been around before, then you could feel embarassed or maybe even get @CAPS4. Movies can help people learn about the real world by seeing how to do those type of things as we get older. Same goes with the magazines, they also help people see what not to do or to help them understand the consequences of something that shouldn't be done. Knowing what to do from a magazine could possible save your life or perhaps maybe even someone elses life.     I don't understand why some libraries would want to banned certain materials to help people understand the things that happen in someone elses life and to help them not make the same mistakes as that person once did.\",\"4\":\"4\",\"5\":\"4\",\"6\":\"4\",\"7\":\"4\",\"8\":\"4\",\"9\":\"4\"},{\"1\":\"2979\",\"2\":\"2\",\"3\":\"Write a persuasive essay to a newspaper reflecting your views on censorship in libraries. Do you believe that certain should be removed i think so be no that yes i think should no person that in chager the book, music, movies, magazines, ect., that be no agure      why do i think if you need that please  think i no thank you please if  i need why do we if know that if i failure the this test i who need to graduate please the children allow to home please yes.          Why do we need to be a prafece person please why do we need to do this why write this assgiment because you mean to be the best teaches ever and ever facebook is my password is @PERSON1  @NUM1 that why i need my myspace is the same thingh but different at same time please know that i need to know i really  i need to my e-mail address is  @EMAIL1 that is my e-mail please work m\",\"4\":\"1\",\"5\":\"2\",\"6\":\"1\",\"7\":\"1\",\"8\":\"2\",\"9\":\"1\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nThe nine columns are:\n\n-   **essay_id:** a unique identifier for the record.\n\n-   **essay_set:** That is set to 2 for all records in this dataset as we are working on essay set 2. We will get rid of this soon.\n\n-   **essay:** The text of the essay written by a real person.\n\n-   There are also 6 more columns that include **rater1_domain1, rater2_domain1, domain1_score, rater1_domain2, rater2_domain2,** and **domain2_score.**\n\nLets see a sample essay which is randomly selected:**\\\n**\n\n\n::: {.cell code_folding='false' filename=''}\n\n```{.r .cell-code  code-fold=\"false\"}\nset.seed(1234)\nrandom_essay <- sample(1:length(essay_set_2), 1)\npaged_table(essay_set_2[random_essay,3])\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"essay\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"A lot of @CAPS3 today are censored because of the content in books, music, movies, and Magazines. I think that it all can be fixed if you have certain sections, @CAPS1 @CAPS2, and my views on the censorship of @CAPS3. Here's my idea to fix the problem.      I understand that books and other material @MONTH1 offend certain people, but it might not offend others. Thats why I think @CAPS3 should have a room for things that might offend certain people. The sign should say what content it has so the people can stay away from the room. There could be seperate rooms for children. It has nothing but children's books, movies, music, and magazines. Its a great idea because your child would'nt be open to the bad content.      This brings me to my next topic. You must be a certain @CAPS1 to enter the 'bad content' room. I dont think the library staff or their parents want a five-year old boy checking out a book that deals with sex, drugs, and alcohol. The library could get in a lot of trouble. The @CAPS1 @CAPS2 could be @NUM1 years of @CAPS1 to enter the room. That seems fair enough. Your old enough to be able to handle the content.      I dont get offended easily, so I can read just about anything. Like I suggested previously in the article, the bad content should be moved to a room so that people dont mistakenly come across it. I like reading about anything and everything, so I would love to read things and spark my attention. Books like that usually deal with bad things. I'm okay with that, but I understand that others are not.      Seperate rooms, @CAPS1 limits, and my views are all good ideas. Maybe a library will come across my article and do what I have said. I think that will be very affective. I hope to start seeing that in the future\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nWe will use the **essay** and **rater1_domain1** columns for our analysis as we are just doing a research for demonstration purposes (of course, when you are working on a real life research case, there are many things that you have to take into consideration). The **essay** column is the text of the essay written by a real person and the **rater1_domain1** column is the score given to the essay by the first rater. We will rename these columns as **response** and **score** respectively. We will also create a new column called **doc_id** which will be a unique identifier for each essay in our case study.\n\n\n::: {.cell code_folding='false' filename=''}\n\n```{.r .cell-code  code-fold=\"false\"}\nset <- essay_set_2 %>% \n  select(essay, rater1_domain1) %>% \n  rename(response = essay, score = rater1_domain1)\nset$doc_id <- paste0(\"doc\", 1:nrow(set))\n```\n:::\n\n\nWhen you scrutinize the essays, you will see that there are some @words in the text. These are the words that are replaced with private information about the students such as names, places or dates etc. Also, there are some non-alphabetic characters and capital letters. In order to make the essays ready to analysis, we will convert all the text to lowercase and remove the non-alphabetic characters. We will also remove the [stopwords](https://en.wikipedia.org/wiki/Stop_word) and lemmatize the text.\n\n\n::: {.cell code_folding='false' filename=''}\n\n```{.r .cell-code  code-fold=\"false\"}\nset$processedResponse <- gsub(\"@\\\\w+ *\", \"\", set$response) #remove @words\nset$processedResponse <- gsub(\"[^a-zA-Z]\", \" \", set$processedResponse) #remove non-alphabetic characters\nset$processedResponse <- tolower(set$processedResponse) #convert to lowercase\nset$processedResponse <- lemmatize_strings(set$processedResponse) #lemmatize\nen_stopwords <- stopwords::stopwords(\"en\", source = \"stopwords-iso\") #get stopwords\nset$processedResponse <- removeWords(set$processedResponse, words = en_stopwords) #remove stopwords\nset$processedResponse <- str_squish(set$processedResponse) #remove extra whitespaces\n```\n:::\n\n\nHere how the new processed text looks like (the one we have seen above):\n\n\n::: {.cell code_folding='false' filename=''}\n\n```{.r .cell-code  code-fold=\"false\"}\nsample_essay<-merge(set[random_essay,4], set[random_essay,1])\npaged_table(sample_essay)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"processedResponse\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"response\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"lot censor content book music movie magazine view censorship understand book material offend people offend offend people sign content people stay seperate child child book movie music magazine child bad content bring topic enter bad content library staff parent boy check book deal sex drug alcohol library lot trouble enter fair handle content offend easily read article bad content people mistakenly read love read spark attention book deal bad understand seperate limit view library article affective hope start future\",\"2\":\"A lot of @CAPS3 today are censored because of the content in books, music, movies, and Magazines. I think that it all can be fixed if you have certain sections, @CAPS1 @CAPS2, and my views on the censorship of @CAPS3. Here's my idea to fix the problem.      I understand that books and other material @MONTH1 offend certain people, but it might not offend others. Thats why I think @CAPS3 should have a room for things that might offend certain people. The sign should say what content it has so the people can stay away from the room. There could be seperate rooms for children. It has nothing but children's books, movies, music, and magazines. Its a great idea because your child would'nt be open to the bad content.      This brings me to my next topic. You must be a certain @CAPS1 to enter the 'bad content' room. I dont think the library staff or their parents want a five-year old boy checking out a book that deals with sex, drugs, and alcohol. The library could get in a lot of trouble. The @CAPS1 @CAPS2 could be @NUM1 years of @CAPS1 to enter the room. That seems fair enough. Your old enough to be able to handle the content.      I dont get offended easily, so I can read just about anything. Like I suggested previously in the article, the bad content should be moved to a room so that people dont mistakenly come across it. I like reading about anything and everything, so I would love to read things and spark my attention. Books like that usually deal with bad things. I'm okay with that, but I understand that others are not.      Seperate rooms, @CAPS1 limits, and my views are all good ideas. Maybe a library will come across my article and do what I have said. I think that will be very affective. I hope to start seeing that in the future\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n## 2. Feature Extraction\n\nFeature extraction is a critical component of Automated Essay Scoring (AES), serving as the foundation upon which the system's evaluation process is built. In AES, feature extraction procedures involve the identification and analysis of various linguistic and structural elements within the essay. These elements may include but are not limited to word frequency, sentence length, syntactic complexity, vocabulary richness, and the presence of specific content-related markers like thesis statements or evidence citations. The goal of feature extraction is to distill the complex nature of written language into a set of quantifiable, machine-readable attributes that can be used by the AES algorithms to assess the quality and coherence of the essay. Through a combination of natural language processing and statistical analysis, feature extraction empowers AES systems to objectively evaluate essays, providing educators and test administrators with consistent, efficient, and data-driven grading outcomes.\n\nFor the sake of simplicity of demonstration, we will extract the following features: **number of sentences**, **number of paragraphs** and **number of contextual words**.\n\n\n::: {.cell code_folding='false' filename=''}\n\n```{.r .cell-code  code-fold=\"false\"}\nset$n_sentence <- nsentence(set$response) \nset$n_paragraph <- str_count(set$response, \"     \") + 1 \nset$n_contextWords <- lengths(strsplit(set$processedResponse, ' '))\nhead(set)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 √ó 7\n  response  score doc_id processedResponse n_sentence n_paragraph n_contextWords\n  <chr>     <dbl> <chr>  <chr>                  <int>       <dbl>          <int>\n1 Certain ‚Ä¶     4 doc1   material remove ‚Ä¶         20           4            126\n2 Write a ‚Ä¶     1 doc2   write persuasive‚Ä¶          3           4             33\n3 Do you t‚Ä¶     2 doc3   library remove m‚Ä¶         15           3             59\n4 In @DATE‚Ä¶     4 doc4   offensive opinio‚Ä¶         31           5            111\n5 In life ‚Ä¶     4 doc5   life offensive s‚Ä¶         35          11            131\n6 A lot of‚Ä¶     4 doc6   lot censor conte‚Ä¶         25           5             79\n```\n\n\n:::\n:::\n\n\nAs stated before, there might be many other features that can be extracted from the essays. We will continue our study with these 3 features even if they are not enough for a real life research.\n\nBefore we start building a machine learning model, we need to divide our dataset as training and test data.\n\n\n::: {.cell code_folding='false' filename=''}\n\n```{.r .cell-code  code-fold=\"false\"}\ndataset <- set\ntrain_indices <- sample(nrow(dataset), nrow(dataset) * 0.7)  # 70% for training\ntrain_data <- dataset[train_indices, ]\ntest_data <- dataset[-train_indices, ]\n```\n:::\n\n\n## 3. Linear Regression Model (LR)\n\n### What is Linear Regression?\n\nLinear regression is a statistical model that examines the linear relationship between two (Simple Linear Regression ) or more (Multiple Linear Regression) variables --- a dependent variable and independent variable(s). Linear relationship basically means that when one (or more) independent variables increases (or decreases), the dependent variable increases (or decreases) too. Linear regression models are used to show or predict the relationship between two variables or factors. The factor that is being predicted (the factor that the equation solves for) is called the dependent variable. The factors that are used to predict the value of the dependent variable are called the independent variables. The results of a LR model can be evaluated using statistical metrics such as **Mean Squared Error (MSE)**, **Root Mean Squared Error (RMSE)** and **R-squared**.\n\nIn our case, the dependent variable is the **score** and the independent variables are **n_sentence**, **n_paragraph** and **n_contextWords**.\n\n\n::: {.cell code_folding='false' filename='Linear Model 1'}\n\n```{.r .cell-code  code-fold=\"false\"}\nformula <- as.formula(\"score ~ n_sentence + n_paragraph + n_contextWords\")\nmodel_1 <- lm(formula, data = train_data)\n# Print the summary of the model\nsummary(model_1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = formula, data = train_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.52359 -0.36412  0.00356  0.40190  1.93435 \n\nCoefficients:\n                Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    2.1864591  0.0418320  52.268  < 2e-16 ***\nn_sentence     0.0224310  0.0027105   8.276 3.23e-16 ***\nn_paragraph    0.0023062  0.0034157   0.675      0.5    \nn_contextWords 0.0076319  0.0005822  13.109  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5595 on 1256 degrees of freedom\nMultiple R-squared:  0.4701,\tAdjusted R-squared:  0.4688 \nF-statistic: 371.4 on 3 and 1256 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n### Performance of the Model 1\n\nLet's investigate the output from the model one by one.\n\n1.  **Residuals:** This section provides statistics about the residuals, which are the differences between the observed values and the predicted values by the model.\n\n    -   **Min:** The minimum residual value is -2.51929.\n\n    -   **1Q:** The first quartile (25th percentile) of the residuals is -0.34048.\n\n    -   **Median:** The median of the residuals is 0.00576.\n\n    -   **3Q:** The third quartile (75th percentile) of the residuals is 0.37803.\n\n    -   **Max:** The maximum residual value is 1.95369.\n\n2.  **Coefficients:** This section provides information about the coefficients of the linear regression model. Each row corresponds to a predictor variable (independent variable) in the model.\n\n3.  **Estimate:** This is the estimated coefficient for each predictor. **Std. Error:** It represents the standard error of the coefficient estimate. **t value:** The t-value is a measure of how many standard errors the coefficient estimate is away from zero. **Pr(\\>\\|t\\|):** This is the p-value associated with the t-value, which tells you whether the coefficient is statistically significant. In our model, we have three predictor variables: n_sentence, n_paragraph, and n_contextWords. The Estimate column represents the estimated coefficients for each of these predictors. The \\*\\*\\* symbols indicate that these coefficients are highly statistically significant. In other words, the number of paragraph is not significantly valuable for the model while the number of sentences and the number of contextual words are highly significant.\n\n4.  **Multiple R-squared:** This is a measure of how well the model fits the data. It tells you the proportion of the variance in the dependent variable that is explained by the independent variables. In our case, R-squared is approximately 0.4737, which means that about 47.37% of the variance in the dependent variable is explained by our predictors.\n\n5.  **Adjusted R-squared:** This is a version of R-squared that adjusts for the number of predictors in the model. It is a slightly more conservative measure of goodness of fit.\n\n6.  **F-statistic:** This is a measure of the overall significance of the model. It tests whether at least one of the predictor variables is significantly related to the dependent variable. A high F-statistic and a very low p-value (which is the case here) indicate that the model is significant.\n\n7.  **p-value:** The p-value associated with the F-statistic. In this case, it's extremely small, indicating that the overall model is highly significant.\n\n### Comparison of Model 1 and Model 2\n\nLet's build another model without the feature **n_paragraph** and compare the results.\n\n\n::: {.cell code_folding='false' filename='Linear Model 2'}\n\n```{.r .cell-code  code-fold=\"false\"}\nformula_2 <- as.formula(\"score ~ n_sentence + n_contextWords\")\nmodel_2 <- lm(formula_2, data = train_data)\n# Print the summary of the model\nsummary(model_2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = formula_2, data = train_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.51924 -0.36470  0.00476  0.39940  1.93587 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    2.195033   0.039849  55.083   <2e-16 ***\nn_sentence     0.022599   0.002698   8.375   <2e-16 ***\nn_contextWords 0.007637   0.000582  13.123   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5594 on 1257 degrees of freedom\nMultiple R-squared:  0.4699,\tAdjusted R-squared:  0.4691 \nF-statistic: 557.1 on 2 and 1257 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n**Residual standard error:** The residual standard error is very close in both models, indicating that they have similar predictive accuracy. **Multiple R-squared:** The R-squared values are also very close. Model 2 has a slightly lower R-squared, but the difference is minimal. **F-statistic:** Model 2 has a higher F-statistic compared to Model 1, indicating that the predictors collectively have more explanatory power in Model 2.\n\nIn summary, both models are quite similar in terms of their coefficient estimates and predictive accuracy. Model 2 has a slightly higher F-statistic. Personally I agree with the model. The number of paragraphs should not be a predictor while estimating the score. The number of sentences and the number of contextual words are much more important.\n\n### Evaluation of Model 2 with the Test Dataset\n\nAs we would like to continue with the second model, we can use the `predict()` to make predictions on the test data. The `predict()` function takes the model and the new data set as arguments. It returns a vector of predictions, which we will save in a new column in the test data set to make comparisons in the next stage. Now, let's use the `mean()` and `sqrt()` functions to calculate the MSE and RMSE of the model. We can also use the `summary()` function to get the R-squared value of the model.\n\n\n::: {.cell code_folding='false' filename=''}\n\n```{.r .cell-code  code-fold=\"false\"}\n# Make predictions on the test data\npredictions <- predict(model_2, newdata = test_data)\n# Evaluate the model\nmse <- mean((test_data$score - predictions)^2)\nrmse <- sqrt(mse)\nr_squared <- summary(model_2)$r.squared\n# Printing evaluation metrics beautifully :D\ncat(paste0(\"Mean Squared Error (MSE): \", sprintf(\"%.2f\", mse), \"\\n\",\n            \"Root Mean Squared Error (RMSE): \", sprintf(\"%.2f\", rmse), \"\\n\",\n            \"R-squared (R¬≤): \", sprintf(\"%.2f\", r_squared), \"\\n\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMean Squared Error (MSE): 0.30\nRoot Mean Squared Error (RMSE): 0.54\nR-squared (R¬≤): 0.47\n```\n\n\n:::\n:::\n\n\n-   **MSE (Mean Squared Error):** MSE is a measure of the average squared difference between the observed (actual) values and the predicted values by the model. It's a measure of the model's accuracy, with lower values indicating a better fit.\n\n-   **RMSE (Root Mean Squared Error):** RMSE is the square root of the MSE and provides a measure of the average error in the same units as the dependent variable. It's a commonly used metric to quantify the prediction error of the model.\n\n-   **R-squared (R¬≤):** R-squared is a measure of how well the independent variables explain the variability in the dependent variable. It ranges from 0 to 1, with higher values indicating a better fit. In the output, the R-squared is approximately 0.4736732, which means that about 47.37% of the variance in the dependent variable is explained by the independent variables in the model.\n\n### Predictions of the Test Dataset\n\nLet's take a look at the predictions of the test data. We can use the `head()` function to print the first 10 predictions.\n\n\n::: {.cell code_folding='false' filename=''}\n\n```{.r .cell-code  code-fold=\"false\"}\n#merge predictions to test data:\ntest_data$predictions <- round(predictions)\nhead(test_data[,c(\"score\",\"predictions\")], 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 √ó 2\n   score predictions\n   <dbl>       <dbl>\n 1     4           4\n 2     1           3\n 3     2           3\n 4     4           4\n 5     5           4\n 6     2           4\n 7     4           3\n 8     3           3\n 9     3           3\n10     3           2\n```\n\n\n:::\n:::\n\n\nBut looking at the raw data would never be enough to get some insights. Let's also print the confusion matrix to get a better overall picture. The **confusion matrix** is a table that is often used to describe the performance of a classification model on a set of test data for which the true values are known. It allows the visualization of the performance of an algorithm. The confusion matrix shows the ways in which the model is confused when it makes predictions. It gives us insight not only into the errors being made by a classifier but more importantly the types of errors that are being made.\n\n\n::: {.cell code_folding='false' filename=''}\n\n```{.r .cell-code  code-fold=\"false\"}\n# Create the confusion matrix and print it\nconfusion_matrix <- table(test_data$predictions, test_data$score)\nconfusion_matrix\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   \n      1   2   3   4   5   6\n  2   7  13   1   0   0   0\n  3   2  35 186  85   1   0\n  4   0   1  30 148  14   0\n  5   0   0   0   7   8   0\n  6   0   0   0   0   1   1\n```\n\n\n:::\n:::\n\n\nIn this context, the confusion matrix helps us understand the model's performance in grading essays. It indicates which score points are frequently confused with others, providing insights into where the model might need improvement. For instance, score points 3 and 4 appear to be frequently confused with each other. Yet, I believe that is not a big deal. Confusing a high score such as 6 with a lower score such as 2 would be a catastrophe in AES context, but here we don't even have one such a case. Besides confusion matrix, one can calculate performance metrics such as accuracy, precision, recall, and F1-score to get a more comprehensive assessment of the model's grading performance.\n\n## Conclusion\n\nOur exploration into AES has shed light on the impressive potential of this technology in revolutionizing the evaluation of written content. Our application of a Linear Regression model, even when considering a limited set of extracted features such as the number of words, sentences, and paragraphs, demonstrated the robustness of this approach. It is evident that by harnessing machine learning algorithms, we can achieve consistent and objective grading, streamlining the assessment process for educators and administrators.\n\nHowever, it's important to note that Linear Regression is just one of the many models available for AES. The field of automated essay scoring continues to evolve, and researchers are exploring a range of models and techniques to enhance accuracy and broaden the scope of assessment. Some alternatives to LR include Support Vector Machines (SVM), Random Forests, Neural Networks, and Natural Language Processing models like Recurrent Neural Networks (RNNs) or Transformers, such as BERT and GPT-3. These models bring their unique strengths and capabilities to the table, offering a diverse array of tools for essay evaluation.\n\nAs AES advances, the synergy of these models with increasingly sophisticated feature extraction procedures promises to further elevate the quality and reliability of automated essay scoring. With this, we look to a future where technology and human expertise collaborate seamlessly to offer more efficient, accurate, and comprehensive assessment in the realm of written expression.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}