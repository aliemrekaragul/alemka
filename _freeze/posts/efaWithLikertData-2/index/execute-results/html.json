{
  "hash": "b4e7abb89d347e3aa10ccb012d862152",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Multidimensional IRT for Factor Exploration\"\ndescription: |\n  This post focuses on multidimensioanl IRT (mIRT) as an exploratory factor analysis method on likert scale data. It is a continuation of the previous post, which was about exploratory factor analysis (EFA) with common factoring using polychoric correlations. The data utilized in the two posts are identical. We also compare factor scores obtained from both mIRT and EFA models.\nauthor:\n  - name: Ali Emre Karag√ºl\n    orcid: 0000-0002-5820-8643\n    email: aliemrekaragul@gmail.com\n    affiliations:\n      - name: TOBB ETU- University of Economics & Technology\ndate: 2024-11-20\ncategories: [psychometrics, Dimension Reduction, Explotary Factor Analysis, IRT, Likert]\nimage: \"image.png\"\noutput:\n    self_contained: false\n    code_folding: false\n---\n\n\n## Introduction\n\nCan we use multidimensional IRT (mIRT) for exploratory factor detection? What is the relation between EFA and mIRT? In fact, EFA is designed to work with continuous observed variables. And, in many cases, researchers use likert type scales to measure psychological constructs. So, that kind of discrete data may not be so suitable for EFA. However, [Takane & Leeuw (1987)](https://link.springer.com/article/10.1007/BF02294363 \"ON THE RELATIONSHIP BETWEEN ITEM RESPONSE THEORY AND FACTOR ANALYSIS OF DISCRETIZED VARIABLES\") put forward that there is a relationship between IRT and EFA. That's why the answer to the question is: Yes, IRT can be used for factor detection, both confirmatory and exploratory.\n\nToday, we will delve into the use of mIRT for exploratory factor analysis. The data we will use is the same as the one used in [the previous post](https://emrekaragul.com/posts/efaWithLikertData-1/) called \"Exploratory Factor Analysis with Likert Scale Data\". So, you can check the preprocessing section of that post to see how we filtered the data.\n\nAlso, in the previous post, we have a detailed discussion about the number of the factors that can be extracted from this data. That's why we are going to skip scree plots, K1, and parallel analysis in this post. I suggest seeing the previous post for those issues.\n\n## Understand the data\n\nThe following code is also provided in the previous post. It is used to load the data and filter the participants based on their demographics. Let's just run the same code to get the data ready for the analysis. If you are coming from the previous post, this code is already run. So, you can skip this part.\n\n\n::: {.cell code_folding='false'}\n\n```{.r .cell-code}\nlibrary(dplyr)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'dplyr'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n```\n\n\n:::\n\n```{.r .cell-code}\ndata <- read.delim(\"data.csv\")\n\ndf_with_demographics <- data %>% \n  filter(engnat == 1) %>% \n  filter(hand == 1) %>% \n  filter(age >= 18 & age <= 30) %>% \n  filter(source == 1)\n\ndf <- df_with_demographics %>% select(1:44)\ndf <- df %>% select(-Q21, -Q43)\n```\n:::\n\n\nJust to remember how the data is distributed, let's see the summary and structure of the data. Remember that we have already discarded items 21 and 43 to avoid multicollinearity because they have high correlation with items 8 and 27 consecutively.\n\n\n::: {.cell code_folding='false'}\n\n```{.r .cell-code  code-fold=\"false\"}\nsummary(df[ ,1:5]) # run summary(df) to see all items.\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       Q1              Q2             Q3          Q4              Q5       \n Min.   :0.000   Min.   :0.00   Min.   :0   Min.   :0.000   Min.   :0.000  \n 1st Qu.:1.000   1st Qu.:2.00   1st Qu.:1   1st Qu.:2.000   1st Qu.:1.000  \n Median :1.000   Median :5.00   Median :3   Median :4.000   Median :3.000  \n Mean   :2.023   Mean   :3.76   Mean   :3   Mean   :3.281   Mean   :2.972  \n 3rd Qu.:3.000   3rd Qu.:5.00   3rd Qu.:5   3rd Qu.:5.000   3rd Qu.:4.000  \n Max.   :5.000   Max.   :5.00   Max.   :5   Max.   :5.000   Max.   :5.000  \n```\n\n\n:::\n\n```{.r .cell-code  code-fold=\"false\"}\nstr(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'data.frame':\t26334 obs. of  42 variables:\n $ Q1 : int  1 1 1 1 1 1 1 1 1 1 ...\n $ Q2 : int  4 1 4 1 5 1 5 5 3 5 ...\n $ Q3 : int  1 4 5 5 1 1 5 1 5 5 ...\n $ Q4 : int  5 4 1 4 5 5 5 5 5 5 ...\n $ Q5 : int  2 5 4 5 1 5 5 1 2 4 ...\n $ Q6 : int  5 4 4 1 5 5 4 5 5 5 ...\n $ Q7 : int  1 5 5 5 1 3 1 3 1 2 ...\n $ Q8 : int  5 5 4 2 5 4 1 4 3 4 ...\n $ Q9 : int  1 4 5 5 1 5 3 1 2 3 ...\n $ Q10: int  4 2 1 3 5 4 2 3 2 1 ...\n $ Q11: int  1 1 3 2 1 5 2 3 1 1 ...\n $ Q12: int  5 4 1 1 5 2 1 4 1 5 ...\n $ Q13: int  5 4 2 1 1 3 1 1 1 1 ...\n $ Q14: int  5 2 5 2 5 2 5 2 1 4 ...\n $ Q15: int  1 4 5 5 1 5 5 3 2 5 ...\n $ Q16: int  1 2 1 1 5 1 5 1 5 5 ...\n $ Q17: int  1 5 1 5 1 2 2 1 1 4 ...\n $ Q18: int  5 2 4 3 1 3 5 5 3 3 ...\n $ Q19: int  1 2 1 3 1 1 5 1 4 2 ...\n $ Q20: int  5 3 4 4 5 1 4 5 1 5 ...\n $ Q22: int  5 4 1 4 5 2 3 4 5 5 ...\n $ Q23: int  4 2 5 2 1 3 4 3 4 3 ...\n $ Q24: int  5 4 1 1 5 1 3 5 2 2 ...\n $ Q25: int  1 5 4 2 1 3 4 1 1 1 ...\n $ Q26: int  5 2 3 2 5 1 5 1 4 5 ...\n $ Q27: int  1 4 4 5 1 5 5 1 1 5 ...\n $ Q28: int  5 4 1 3 5 1 4 4 1 4 ...\n $ Q29: int  1 1 1 1 1 3 5 1 5 1 ...\n $ Q30: int  5 1 2 2 5 1 3 5 5 4 ...\n $ Q31: int  1 5 1 4 1 3 1 1 5 4 ...\n $ Q32: int  5 4 1 5 5 1 1 5 1 4 ...\n $ Q33: int  1 5 3 3 1 2 4 1 2 3 ...\n $ Q34: int  5 5 4 4 5 1 3 1 5 5 ...\n $ Q35: int  1 4 5 2 1 5 5 1 5 5 ...\n $ Q36: int  3 2 3 1 5 1 1 4 3 4 ...\n $ Q37: int  1 1 5 5 1 4 4 1 5 3 ...\n $ Q38: int  5 4 4 1 5 1 1 3 5 5 ...\n $ Q39: int  1 2 2 1 1 5 5 1 5 5 ...\n $ Q40: int  4 3 4 3 5 1 5 2 3 5 ...\n $ Q41: int  1 4 4 5 1 4 5 1 5 4 ...\n $ Q42: int  5 1 5 2 5 1 2 4 1 2 ...\n $ Q44: int  5 3 4 1 5 1 5 5 5 4 ...\n```\n\n\n:::\n:::\n\n\n## Multidimensional IRT Model Building\n\n### Initial Model\n\nIn this post, we are going to build 2-factor model as all the previous analyses suggest that 2-factor model is the best fit for this data. The factors are defined as *Masculinity* and *Femininity* by the origibal authors of the scale.\n\n::: callout-note\nNote on Item Selection\n\nThe item selection processes for both mIRT and EFA are described in the literature strictly, although subjectivity within the boundaries of these definitions may still exist. In other words, although most decisions will be the same, there may be some differences among psychometricians in terms of selecting/discarding an item. One psychometrician might select an item while another might not. And, both might have their logical reasons. The reasoning behind selecting/discarding items might depend on both statistics and knowledge of construct that is being assessed. Thus, although I am not an expert in gender roles, I wanted this post to be a personal experiment to check if I can extract the same factors and items as the original authors. So, **I avoided checking the items in the original scale developed by the authors.** See the documentation of the scale for the original items [here.](https://openpsychometrics.org/tests/OSRI/development/ \"documentation\")\n:::\n\nLet's build the model with the `mirt` package.\n\n\n::: {.cell code_folding='false'}\n\n```{.r .cell-code  code-fold=\"false\"}\nlibrary(mirt)\nmodel_1 <- mirt(df, 2, itemtype = 'graded', method = 'EM', verbose = FALSE)\nmodel_1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nmirt(data = df, model = 2, itemtype = \"graded\", method = \"EM\", \n    verbose = FALSE)\n\nFull-information item factor analysis with 2 factor(s).\nConverged within 1e-04 tolerance after 236 EM iterations.\nmirt version: 1.42 \nM-step optimizer: BFGS \nEM acceleration: Ramsay \nNumber of rectangular quadrature: 31\nLatent density type: Gaussian \n\nLog-likelihood = -1590607\nEstimated parameters: 293 \nAIC = 3181800\nBIC = 3184196; SABIC = 3183265\nG2 (1e+10) = 2645146, p = 1\nRMSEA = 0, CFI = NaN, TLI = NaN\n```\n\n\n:::\n:::\n\n\nThe \\``mirt()` is a function built in the mirt package to build multidimensional IRT models. It takes a dataframe, number of factors, IRT model, method etc. In our model, we use the prominent Graded Response Model (GRM) that is suitable for Likert scale ordinal data. \"EM\", which stands for \"Expectation-Maximization\", is the default estimation method and suggested for models with less than 3 factors. The `verbose = FALSE` argument is used to suppress the output of the function after each iteration cycle.\n\nWith the `coef()` function of mirt package, we can get the item parameters such as discrimination and difficulty.\n\n\n::: {.cell code_folding='false'}\n\n```{.r .cell-code  code-fold=\"false\"}\nitem_params <- coef(model_1, simplify = TRUE)$items\nprint(head(item_params)) # run print(item_params) to see all items.\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           a1          a2       d1         d2         d3          d4\nQ1  0.5428696 -0.87427291 7.469361 -0.4101088 -0.9383750 -1.53030916\nQ2 -1.3926877  0.10494528 7.617294  1.9428222  1.4265050  0.99922695\nQ3  0.3767874 -1.84457406 8.098128  1.1101457  0.4213897 -0.18057288\nQ4 -1.2437652 -0.22953251 6.872875  1.8390821  0.9332445  0.06892971\nQ5  0.2059426 -0.98529256 6.896770  1.1428991  0.4112459 -0.30738685\nQ6 -0.3865773  0.04663095 6.864864  2.3255300  1.4584706  0.64351628\n            d5\nQ1 -2.80068782\nQ2  0.08154265\nQ3 -1.33340228\nQ4 -1.21175535\nQ5 -1.40389522\nQ6 -0.52337385\n```\n\n\n:::\n:::\n\n\nIn the case of factor analysis with MIRT, discrimination parameters are referred as the slope of the item characteristic surface (ICS). `a1` is the slope of the item on Factor 1, while `a2` is the slope of the item on Factor 2. Positive or negative values indicate the direction and strength of the relationship between the item and the respective factor.\n\n`d1`, `d2`, `d3`, `d4` and `d5` are the difficulty parameters of the items. They are also called as the threshold parameters. They represent the intercepts of the item for each category in the likert scale. Thresholds should increase monotonically (d1 \\> d2 \\> d3 \\> ...) for well-functioning items. Non-monotonic thresholds suggest problems with item performance. To detect these items, we can use the following function. It is expected to print the index of problematic items.\n\n\n::: {.cell code_folding='false'}\n\n```{.r .cell-code  code-fold=\"false\"}\ncheck_monotonic <- function(data) {\n  d_columns <- data[, grepl(\"^d\\\\d+$\", names(data))]\n  \n  non_monotonic <- logical(nrow(d_columns))\n  \n  for (i in seq_len(nrow(d_columns))) {\n    non_monotonic[i] <- any(diff(as.numeric(d_columns[i, ])) < 0)\n  }\n  \n  which(non_monotonic)\n}\ncheck_monotonic(item_params)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ninteger(0)\n```\n\n\n:::\n:::\n\n\nThe output is null, suggesting all the items have monotonic thresholds.\n\nThe `summary()` function provides us with the factor loadings and the communalities (h2) of the variables. The default rotation method is oblimin. Therfore, we provide `rotate = \"none\"` in the function. Below the factor loadings, we can see the explained variance by each factor. The first factor explains %17.6 of the variance, while the second factor explains %10.8. Also, the correlation between the factors seems to be zero. Oblique rotations (e.g., oblimin) allow factors to be correlated, providing these estimates directly. As we set the rotation to none, the correlation between the factors is not calculated. Yet, we will get the correlation scores after we apply a rotation.\n\n\n::: {.cell code_folding='false'}\n\n```{.r .cell-code  code-fold=\"false\"}\nsummary(model_1, rotate = \"none\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nUnrotated factor loadings: \n\n         F1        F2     h2\nQ1   0.2729 -0.439568 0.2677\nQ2  -0.6326  0.047666 0.4024\nQ3   0.1485 -0.726795 0.5503\nQ4  -0.5865 -0.108245 0.3558\nQ5   0.1041 -0.498283 0.2591\nQ6  -0.2214  0.026708 0.0497\nQ7   0.2366 -0.400577 0.2164\nQ8  -0.4228  0.126203 0.1947\nQ9   0.3049 -0.576922 0.4258\nQ10 -0.2790  0.051659 0.0805\nQ11  0.1865 -0.215908 0.0814\nQ12 -0.5260  0.171620 0.3061\nQ13  0.4317 -0.091842 0.1948\nQ14 -0.5978 -0.035233 0.3586\nQ15  0.0794 -0.610298 0.3788\nQ16 -0.6210  0.050615 0.3882\nQ17  0.1866 -0.542158 0.3288\nQ18 -0.3000 -0.082622 0.0968\nQ19  0.4003 -0.276375 0.2366\nQ20 -0.6201  0.163312 0.4112\nQ22 -0.5505  0.050788 0.3056\nQ23  0.0277 -0.341561 0.1174\nQ24 -0.4089  0.102879 0.1778\nQ25  0.3163 -0.396559 0.2573\nQ26 -0.5752 -0.007970 0.3310\nQ27  0.1348 -0.523084 0.2918\nQ28 -0.5349  0.021320 0.2866\nQ29  0.1100 -0.583130 0.3521\nQ30 -0.5607  0.042580 0.3162\nQ31  0.4048 -0.284227 0.2447\nQ32 -0.3573  0.095665 0.1368\nQ33  0.4155 -0.185081 0.2069\nQ34 -0.5225  0.054848 0.2760\nQ35  0.1540 -0.588756 0.3704\nQ36 -0.5778  0.047455 0.3361\nQ37  0.2797 -0.314347 0.1771\nQ38 -0.6441 -0.015461 0.4151\nQ39  0.1609 -0.744320 0.5799\nQ40 -0.5856 -0.025633 0.3436\nQ41  0.1618 -0.362005 0.1572\nQ42 -0.5156 -0.000675 0.2659\nQ44 -0.6280  0.000000 0.3943\n\nSS loadings:  7.399 4.525 \nProportion Var:  0.176 0.108 \n\nFactor correlations: \n\n   F1 F2\nF1  1   \nF2  0  1\n```\n\n\n:::\n:::\n\n\nBefore we apply a rotation, we need to check communalities to be over 0.30 just as it is in EFA. Communalities do not change after rotation, so we can discard the items with communalities below 0.30 at this stage. Here is the code to print the communalities below 0.3:\n\n\n::: {.cell code_folding='false'}\n\n```{.r .cell-code  code-fold=\"false\"}\ncommunalities <- data.frame(value = model_1@Fit[[\"h2\"]])\nlow_communalities <- communalities[communalities$value < 0.3, , drop = FALSE]\n\n# print ordered by communality value:\nprint(low_communalities[order(low_communalities$value), , drop = FALSE])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         value\nQ6  0.04973608\nQ10 0.08049372\nQ11 0.08140447\nQ18 0.09683406\nQ23 0.11743292\nQ32 0.13679041\nQ41 0.15723452\nQ37 0.17705607\nQ24 0.17778655\nQ8  0.19465828\nQ13 0.19482647\nQ33 0.20685832\nQ7  0.21643984\nQ19 0.23662033\nQ31 0.24466433\nQ25 0.25733267\nQ5  0.25913279\nQ42 0.26588832\nQ1  0.26771912\nQ34 0.27603944\nQ28 0.28656914\nQ27 0.29178386\n```\n\n\n:::\n:::\n\n\n### Final Model\n\nItems with low communality values can be discarded from the dataset. To do that, run the following code:\n\n\n::: {.cell code_folding='false'}\n\n```{.r .cell-code  code-fold=\"false\"}\ndiscard_these_items <- rownames(low_communalities)\nprint(discard_these_items)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"Q1\"  \"Q5\"  \"Q6\"  \"Q7\"  \"Q8\"  \"Q10\" \"Q11\" \"Q13\" \"Q18\" \"Q19\" \"Q23\" \"Q24\"\n[13] \"Q25\" \"Q27\" \"Q28\" \"Q31\" \"Q32\" \"Q33\" \"Q34\" \"Q37\" \"Q41\" \"Q42\"\n```\n\n\n:::\n\n```{.r .cell-code  code-fold=\"false\"}\ndf_final <- df %>% select(-discard_these_items)\n```\n:::\n\n\nNow, using the `df_final`, we can build our final solution:\n\n\n::: {.cell code_folding='false'}\n\n```{.r .cell-code  code-fold=\"false\"}\nmodel_2 <- mirt(df_final, 2, itemtype = 'graded', method = 'EM', verbose = FALSE)\nmodel_2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nmirt(data = df_final, model = 2, itemtype = \"graded\", method = \"EM\", \n    verbose = FALSE)\n\nFull-information item factor analysis with 2 factor(s).\nConverged within 1e-04 tolerance after 184 EM iterations.\nmirt version: 1.42 \nM-step optimizer: BFGS \nEM acceleration: Ramsay \nNumber of rectangular quadrature: 31\nLatent density type: Gaussian \n\nLog-likelihood = -752201.4\nEstimated parameters: 139 \nAIC = 1504681\nBIC = 1505818; SABIC = 1505376\nG2 (1e+10) = 968649.2, p = 1\nRMSEA = 0, CFI = NaN, TLI = NaN\n```\n\n\n:::\n:::\n\n\nLet's see the factor loadings for the final solution. If we need to, we can apply a rotation later on:\n\n\n::: {.cell code_folding='false'}\n\n```{.r .cell-code  code-fold=\"false\"}\nsummary(model_2, rotate = \"none\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nUnrotated factor loadings: \n\n        F1      F2    h2\nQ2   0.605  0.0369 0.368\nQ3  -0.148 -0.7520 0.587\nQ4   0.575 -0.1099 0.343\nQ9  -0.297 -0.5812 0.426\nQ12  0.511  0.1587 0.286\nQ14  0.634 -0.0172 0.402\nQ15 -0.078 -0.5531 0.312\nQ16  0.624  0.0593 0.393\nQ17 -0.183 -0.5115 0.295\nQ20  0.596  0.1708 0.385\nQ22  0.541  0.0636 0.297\nQ26  0.593  0.0153 0.351\nQ29 -0.109 -0.6068 0.380\nQ30  0.542  0.0504 0.296\nQ35 -0.145 -0.5846 0.363\nQ36  0.577  0.0392 0.334\nQ38  0.651 -0.0059 0.424\nQ39 -0.159 -0.7813 0.636\nQ40  0.630 -0.0200 0.397\nQ44  0.611  0.0000 0.374\n\nSS loadings:  4.777 2.872 \nProportion Var:  0.239 0.144 \n\nFactor correlations: \n\n   F1 F2\nF1  1   \nF2  0  1\n```\n\n\n:::\n:::\n\n\nThe factor loadings and communalities of the final solution looks fine. The explained variance by each factor is %23.9 and %14.4, respectively. This suggests an increase in the explained variance by the factors when compared to the initial model. Now, we can apply a rotation to see the correlation of the factors.\n\n\n::: {.cell code_folding='false'}\n\n```{.r .cell-code  code-fold=\"false\"}\nsummary(model_2, rotate = \"oblimin\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nRotation:  oblimin \n\nRotated factor loadings: \n\n         F1       F2    h2\nQ2   0.6020 -0.01689 0.368\nQ3   0.0252  0.77249 0.587\nQ4   0.6058  0.13388 0.343\nQ9  -0.1646  0.59058 0.426\nQ12  0.4781 -0.14616 0.286\nQ14  0.6431  0.04007 0.402\nQ15  0.0496  0.56925 0.312\nQ16  0.6158 -0.03944 0.393\nQ17 -0.0663  0.52252 0.295\nQ20  0.5618 -0.15568 0.385\nQ22  0.5310 -0.04682 0.297\nQ26  0.5941  0.00498 0.351\nQ29  0.0308  0.62368 0.380\nQ30  0.5345 -0.03308 0.296\nQ35 -0.0107  0.59951 0.363\nQ36  0.5724 -0.02029 0.334\nQ38  0.6576  0.02896 0.424\nQ39  0.0204  0.80238 0.636\nQ40  0.6397  0.04283 0.397\nQ44  0.6164  0.02147 0.374\n\nRotated SS loadings:  4.572 3.009 \n\nFactor correlations: \n\n       F1 F2\nF1  1.000   \nF2 -0.257  1\n```\n\n\n:::\n:::\n\n\nThe correlation between the factors is -0.26 after the rotation. This is a good result as it is not too high to suggest a single factor solution, nor too low to suggest a completely independent factor solution.\n\n### Model Fit\n\nTo see model's fit indices, we can use `M2()` of mirt:\n\n\n::: {.cell code_folding='false'}\n\n```{.r .cell-code  code-fold=\"false\"}\nM2(model_2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            M2 df p      RMSEA    RMSEA_5   RMSEA_95      SRMSR      TLI\nstats 5090.389 71 0 0.05181388 0.05061086 0.05302509 0.03886059 0.914146\n            CFI\nstats 0.9445851\n```\n\n\n:::\n:::\n\n\nThe model fit indices are suggesting a good model fit. RMSEA and SRMSR values are below 0.08 and TLI and CFI are above 0.90. These values are considered as good fit indices for a model.\n\n### Visualization\n\nThe MIRT package provides with 3D plotting options. We can use the `plot()` and `itemplot()` functions to see the 3D plots of the model. We can also implement rotation to see the rotated model's plot.\n\n#### Expected Total Score Plot\n\n\n::: {.cell code_folding='false'}\n\n```{.r .cell-code  code-fold=\"false\"}\nplot(model_2)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n\n```{.r .cell-code  code-fold=\"false\"}\nplot(model_2, rotate = \"oblimin\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-13-2.png){width=672}\n:::\n:::\n\n\n#### Item Trace Plots\n\nWe can also check for item trace plots. Let's see the first item's trace plot for final model without rotation and with rotation:\n\n\n::: {.cell code_folding='false'}\n\n```{.r .cell-code  code-fold=\"false\"}\nitemplot(model_2, 1)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n\n```{.r .cell-code  code-fold=\"false\"}\nitemplot(model_2, 1, rotate = \"oblimin\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-14-2.png){width=672}\n:::\n:::\n\n\n#### Test Information\n\nWe can also draw a plot to see the test information. Test information is a measure of the precision of the test at different levels of the latent traits. In multidimensional models we need to produce a contour plot.\n\nWe can plot the test information with the following code:\n\n\n::: {.cell code_folding='false'}\n\n```{.r .cell-code  code-fold=\"false\"}\nplot(model_2, rotate = \"oblimin\" ,type=\"infocontour\") \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\nThe test is most effective (provides the highest precision) in the central regions where test information is high (contour values like 6 or 7). Meaning the test is most effective for around 0 thetas of both factors. At the edges of the plot, the test is less precise (values like 1 or 2), meaning the test is less effective at distinguishing individuals with very high or very low abilities in those dimensions.\n\n### Selected Items and Defining Factors\n\nWe are solid that our data has 2 factors, with each variable loading to a single factor. These factors were named as **Femininity** and **Masculinity** in the original scale.\n\nThese are the factors and their variables.\n\n| Femininity                                                                | Masculinity                                                              |\n|------------------------------------|------------------------------------|\n| Q2 I have thought about dying my hair.                                    | Q3 I have thrown knives, axes or other sharp things.                     |\n| Q4 I give people handmade gifts.                                          | Q9 I like guns.                                                          |\n| Q12 I use lotion on my hands.                                             | Q15 I have thought it would be exciting to be an outlaw.                 |\n| Q14 I dance when I am alone.                                              | Q17 I have considered joining the military.                              |\n| Q16 When I was a child, I put on fake concerts and plays with my friends. | Q29 I have burned things up with a magnifying glass.                     |\n| Q20 I sometimes feel like crying when I get angry.                        | Q35 I have taken apart machines just to see how they work.               |\n| Q22 I save the letters I get.                                             | Q39 I have set fuels, aerosols or other chemicals on fire, just for fun. |\n| Q26 I jump up and down in excitement sometimes.                           |                                                                          |\n| Q30 I think horoscopes are fun.                                           |                                                                          |\n| Q36 I take lots of pictures of my activities.                             |                                                                          |\n| Q38 I leave nice notes for people now and then.                           |                                                                          |\n| Q40 I really like dancing.                                                |                                                                          |\n| Q44 I decorate my things (e.g. stickers on laptop).                       |                                                                          |\n\n### Factor scores of persons\n\nFinally, we can extract the factor scores of the persons. These scores can be used in further analyses such as regression, clustering, etc.\n\n\n::: {.cell code_folding='false'}\n\n```{.r .cell-code  code-fold=\"false\"}\nhead(fscores(model_2)) ## run fscores(model_2) to see all scores.\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n             F1         F2\n[1,]  1.9183653 -2.0882425\n[2,] -0.5932079  0.4430873\n[3,] -0.3261666  0.7950392\n[4,] -1.4358888  0.6969259\n[5,]  3.1571670 -2.2801150\n[6,] -2.3165436  1.3256648\n```\n\n\n:::\n:::\n\n\nAs we did in EFA in the previous post, we can use these factor scores in a scree plot with genders of the participants. Let's see the plot:\n\n\n::: {.cell code_folding='false'}\n\n```{.r .cell-code  code-fold=\"false\"}\nlibrary(ggplot2)\nmirt_scores <- fscores(model_2)\ncolnames(mirt_scores) <- c(\"Femininity\", \"Masculinity\")\nscores <- as_tibble(mirt_scores)\nscores <- bind_cols(df_with_demographics |> select(gender), scores) |>\n  filter(gender %in% c(1, 2)) |>  \n  mutate(gender = factor(gender, labels = c(\"Male\", \"Female\")))  \n\n# Plot the filtered data\nscores |>\n  ggplot(aes(Femininity, Masculinity, color = gender)) +\n  geom_point() +\n  theme_minimal() +\n  theme(legend.position = \"bottom\") +\n  labs(color = \"Gender\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\nIn my opinion this plot's being parallelogram-like is interesting. The same plot in EFA was more like a rectangle, although both distributions are similar.\n\n### Comparison with EFA Model\n\nIt is also a good idea to check the correlation between the factor scores obtained from mIRT and EFA.\n\nLet's build the EFA model again:\n\n\n::: {.cell code_folding='false'}\n\n```{.r .cell-code  code-fold=\"false\"}\nlibrary(psych)\ndf_EFA <- df %>% select(\n  -Q6, -Q11, -Q10, -Q18, -Q23, -Q32, -Q37, -Q41, \n  -Q24, -Q8, -Q13, -Q33, -Q7, -Q19, -Q31, -Q42, \n  -Q25, -Q34, -Q28, -Q5, -Q1, -Q12, -Q27, -Q30, -Q22\n  )\n\n\npoly_matrix <- polychoric(df_EFA)$rho\n\ntwo_fm <- fa(poly_matrix, nfactors = 2, fm = \"pa\", rotate = \"oblimin\", cor = \"poly\", SMC=FALSE)\n```\n:::\n\n\nRemember that although the items selected by EFA and IRT are very similar, they are not identical. We can compare the items selected by both methods:\n\n\n::: {.cell code_folding='false'}\n\n```{.r .cell-code  code-fold=\"false\"}\nmirt_items<-colnames(df_final)\nefa_items<-colnames(df_EFA)\nall_items <- unique(c(mirt_items, efa_items)) \n\ncomparison <- data.frame(\n  mirt_items = ifelse(all_items %in% mirt_items, all_items, \"\"),\n  efa_items = ifelse(all_items %in% efa_items, all_items, \"\")\n)\n\nprint(comparison)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   mirt_items efa_items\n1          Q2        Q2\n2          Q3        Q3\n3          Q4        Q4\n4          Q9        Q9\n5         Q12          \n6         Q14       Q14\n7         Q15       Q15\n8         Q16       Q16\n9         Q17       Q17\n10        Q20       Q20\n11        Q22          \n12        Q26       Q26\n13        Q29       Q29\n14        Q30          \n15        Q35       Q35\n16        Q36       Q36\n17        Q38       Q38\n18        Q39       Q39\n19        Q40       Q40\n20        Q44       Q44\n```\n\n\n:::\n:::\n\n\nSo items 12, 22, and 30 are selected by IRT model but they are not selected by EFA model.\n\nNow let's have a look at the correlation between factor scores obtained from mIRT and EFA models:\n\n\n::: {.cell code_folding='false'}\n\n```{.r .cell-code  code-fold=\"false\"}\nefa_scores  <- factor.scores(df_EFA, two_fm)$scores\ncolnames(efa_scores) <- c(\"Femininity_efa\", \"Masculinity_efa\")\ncor(mirt_scores, efa_scores)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            Femininity_efa Masculinity_efa\nFemininity       0.9741479      -0.3107335\nMasculinity     -0.3301980       0.9873525\n```\n\n\n:::\n:::\n\n\nThe participants' scores obtained from MIRT and EFA models are highly correlated. The correlation between the femininity scores is 0.98, while the correlation between the masculinity scores is 0.99. This suggests that the factor scores obtained from both models are very similar.\n\n## Conclusion\n\nIn this post, we worked on how to run multidimensional Item Response Theory based exploratory factor analysis on likert scale data. We used the `mirt` package in R to build the model. We also compared the factor scores obtained from the mIRT model with the factor scores obtained from the EFA model, which was discussed in my previous post. The results suggest that the factor scores from both models are highly correlated. Also, the mIRT model has shown great fit, even better than EFA model. These findings supports the opinion that as EFA is designed to work on continuous data, mIRT is a good alternative for factor detection in likert scale data.\n\n### Comparison with the Original Scale\n\nBoth my EFA and mIRT models have similar items to the original scale. However, the scales are not identical. The original scale contains 10 items for each factor. The difference occurs because of the variation in our approaches in two ways:\n\n1.  I discarded two items because they are highly correlated with other two items, pointing to multicollinearity issues. It wasn't done on the original scale. This might be because the authors might not have this issue in their original data. This difference probably resulted in the alternation in the item selection processes.\n\n2.  The preferred rotation method is different in the original scale. Although this shouldn't make an effect on item selection for the factors, the participants' factor scores might slightly alter. I used oblimin rotation while the original authors used varimax. The varimax is usually preferred when factors are independent of each other (no correlation between factors). The aim of varimax rotation is to maximize the variance of the squared loadings. Thus, it creates a simpler structure and encourages each variable to load strongly on one factor and weakly on others. Assuming the factors (Femininity and Masculinity) are independent of each other, the original authors might have used varimax rotation. In my personal opinion, these two factors could be considered as correlated negatively. That's why I used oblimin rotation. Yet, as I mentioned before, I am not an expert on gender roles. So, I might be wrong in this assumption. In a real case study, I would definitely consult with an expert in the field to decide on the rotation method.\n\n## Further Remarks\n\n-   Running Confirmatory Factor Analysis (CFA) and mIRT for confirmatory factor detection is planned for a future post.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}