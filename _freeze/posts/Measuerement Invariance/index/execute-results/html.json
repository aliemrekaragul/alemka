{
  "hash": "602f98361cacc1fd30f56ad75fdf6ead",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Measurement Invariance\"\ndescription: |\n  Measurement invariance (MI) is essential in psychometrics to ensure that a test measures the same construct across different sub-groups of the population. Therefore, it is also considered as a validity problem. Without MI, comparing group differences could lead to misleading conclusions. Essentially, MI tests whether the relationships between observed items and the latent variables they represent are equivalent across smaller groups (gender, age etc). Achieving MI in a test will help us ensure that any differences in scores are because of true differences in the latent trait, not the measurement bias.\nauthor:\n  - name: Ali Emre Karagül\n    orcid: 0000-0002-5820-8643\n    email: aliemrekaragul@gmail.com\n    affiliations:\n      - name: TOBB ETU- University of Economics & Technology\ndate: 2024-10-15\ncategories: [psychometrics, measusrement invariance, Big data, SEM, Data-viz]\nimage: \"measurement_invariance.png\"\noutput:\n    self_contained: false\n    code_folding: false\n---\n\n\n## Introduction\n\nMeasurement invariance is critical because if a test is not invariant across groups, differences in test scores might reflect biases in how questions are interpreted. For instance, a math test may appear to show that boys score higher than girls, but this could be because certain items function differently for each group.\n\nThere are different levels of MI:\n\n**Configural Invariance:** Tests whether the overall factor structure (i.e., the number and pattern of factors) is the same across groups. It is the smallest restrictive form of invariance. It allows us to conclude that the groups conceptualize the construct in the same way.\n\n**Metric (Weak) Invariance:** Tests whether the factor loadings (the strength of the relationship between each item and the latent factor) are equal across groups. This ensures that the items are equally good indicators of the latent construct in all groups.\n\n**Scalar (Strong) Invariance:** Tests whether item intercepts are equal across groups. Scalar invariance is necessary for comparing latent means between groups.\n\n**Strict Invariance:** Tests whether item residual variances are equal across groups. It’s the strongest form of invariance, implying that the amount of measurement error is consistent across groups.\n\nIn the context of R, we can use structural equation modeling (SEM) to assess MI. The `lavaan` package provides a dataset (`HolzingerSwineford1939`) for several SEM analysis including MI. Let's load the `lavaan` and `HolzingerSwineford1939` data along with the `semTools` package for visualization.\n\n::: {layout-ncol=\"2\"}\n\n::: {.cell code_folding='true' filename='Requirements'}\n\n```{.r .cell-code  code-fold=\"true\"}\n# requirements\nlibrary(\"lavaan\")\nlibrary(\"semPlot\")# For additional tools related to SEM\nlibrary(\"ggplot2\")\nlibrary(\"semTools\")\n```\n:::\n\n:::\n\n## 1. Understand the data\n\nLet's load the data and see the head of them:\n\n\n::: {.cell code_folding='true' filename=''}\n\n```{.r .cell-code  code-fold=\"true\"}\ndata(\"HolzingerSwineford1939\")\nhead(HolzingerSwineford1939)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  id sex ageyr agemo  school grade       x1   x2    x3       x4   x5        x6\n1  1   1    13     1 Pasteur     7 3.333333 7.75 0.375 2.333333 5.75 1.2857143\n2  2   2    13     7 Pasteur     7 5.333333 5.25 2.125 1.666667 3.00 1.2857143\n3  3   2    13     1 Pasteur     7 4.500000 5.25 1.875 1.000000 1.75 0.4285714\n4  4   1    13     2 Pasteur     7 5.333333 7.75 3.000 2.666667 4.50 2.4285714\n5  5   2    12     2 Pasteur     7 4.833333 4.75 0.875 2.666667 4.00 2.5714286\n6  6   2    14     1 Pasteur     7 5.333333 5.00 2.250 1.000000 3.00 0.8571429\n        x7   x8       x9\n1 3.391304 5.75 6.361111\n2 3.782609 6.25 7.916667\n3 3.260870 3.90 4.416667\n4 3.000000 5.30 4.861111\n5 3.695652 6.30 5.916667\n6 4.347826 6.65 7.500000\n```\n\n\n:::\n:::\n\n\nThe **Holzinger and Swineford** dataset contains data on students’ cognitive abilities, including variables like **sex**, **age**, and **grade**. It also includes information about the school of students. It includes several cognitive test scores (variables x1 to x9) that measure different abilities, which can be used to examine latent traits. These variables and code for the model is provided in the package's own paper. The dataset measures three latent factors:\n\n-   **Visual** (x1, x2, x3),\n\n-   **Textual** (x4, x5, x6),\n\n-   **Speed** (x7, x8, x9).\n\n## 2. Fit the base model\n\nLet's specify the CFA model.\n\n\n::: {.cell code_folding='true' filename=''}\n\n```{.r .cell-code  code-fold=\"true\"}\nHS.model <- ' visual  =~ x1 + x2 + x3\n              textual =~ x4 + x5 + x6\n              speed   =~ x7 + x8 + x9 '\n```\n:::\n\n\nWe fit the model using the entire dataset without considering groups. This step provides a baseline understanding of how well the model fits:\n\n\n::: {.cell code_folding='true' filename=''}\n\n```{.r .cell-code  code-fold=\"true\"}\nfit <- lavaan(HS.model, data = HolzingerSwineford1939, \n              auto.var = TRUE, auto.fix.first = TRUE,\n              auto.cov.lv.x = TRUE)\nsummary(fit, fit.measures = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nlavaan 0.6-19 ended normally after 35 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        21\n\n  Number of observations                           301\n\nModel Test User Model:\n                                                      \n  Test statistic                                85.306\n  Degrees of freedom                                24\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                               918.852\n  Degrees of freedom                                36\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.931\n  Tucker-Lewis Index (TLI)                       0.896\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -3737.745\n  Loglikelihood unrestricted model (H1)      -3695.092\n                                                      \n  Akaike (AIC)                                7517.490\n  Bayesian (BIC)                              7595.339\n  Sample-size adjusted Bayesian (SABIC)       7528.739\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.092\n  90 Percent confidence interval - lower         0.071\n  90 Percent confidence interval - upper         0.114\n  P-value H_0: RMSEA <= 0.050                    0.001\n  P-value H_0: RMSEA >= 0.080                    0.840\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.065\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  visual =~                                           \n    x1                1.000                           \n    x2                0.554    0.100    5.554    0.000\n    x3                0.729    0.109    6.685    0.000\n  textual =~                                          \n    x4                1.000                           \n    x5                1.113    0.065   17.014    0.000\n    x6                0.926    0.055   16.703    0.000\n  speed =~                                            \n    x7                1.000                           \n    x8                1.180    0.165    7.152    0.000\n    x9                1.082    0.151    7.155    0.000\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  visual ~~                                           \n    textual           0.408    0.074    5.552    0.000\n    speed             0.262    0.056    4.660    0.000\n  textual ~~                                          \n    speed             0.173    0.049    3.518    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n   .x1                0.549    0.114    4.833    0.000\n   .x2                1.134    0.102   11.146    0.000\n   .x3                0.844    0.091    9.317    0.000\n   .x4                0.371    0.048    7.779    0.000\n   .x5                0.446    0.058    7.642    0.000\n   .x6                0.356    0.043    8.277    0.000\n   .x7                0.799    0.081    9.823    0.000\n   .x8                0.488    0.074    6.573    0.000\n   .x9                0.566    0.071    8.003    0.000\n    visual            0.809    0.145    5.564    0.000\n    textual           0.979    0.112    8.737    0.000\n    speed             0.384    0.086    4.451    0.000\n```\n\n\n:::\n:::\n\n\n-   **Chi-Square Test (85.306, df = 24, p \\< 0.001)**: The significant result indicates that the model doesn’t perfectly fit the data, but Chi-square is highly sensitive to sample size.\n\n-   **CFI (0.931)**: This value suggests a reasonably good fit (values above 0.90 are typically considered acceptable).\n\n-   **RMSEA (0.092)**: The RMSEA is below the threshold for a good fit (\\<0.10).\n\n-   **SRMR (0.065)**: This is below 0.10.\n\nAll latent variables (visual, textual, speed) show significant factor loadings for their respective observed variables (e.g., x1–x3 for visual), indicating that these items effectively measure their intended constructs.\n\nCovariances between latent variables (visual, textual, speed) are significant, indicating meaningful relationships between these cognitive abilities.\\\n\n## 3. Measurement Invariance\n\nNow we move on to measurement invariance.\n\n### 3.1. Configural Invariance\n\nThe first step is testing **configural invariance**, which checks whether the factor structure (i.e., the number of factors and their loadings) is the same across groups. We’ll use **school** as the grouping variable:\n\n\n::: {.cell code_folding='true' filename=''}\n\n```{.r .cell-code  code-fold=\"true\"}\nfit_configural <- cfa(HS.model, data = HolzingerSwineford1939, group = \"school\")\nsummary(fit_configural, fit.measures = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nlavaan 0.6-19 ended normally after 57 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        60\n\n  Number of observations per group:                   \n    Pasteur                                        156\n    Grant-White                                    145\n\nModel Test User Model:\n                                                      \n  Test statistic                               115.851\n  Degrees of freedom                                48\n  P-value (Chi-square)                           0.000\n  Test statistic for each group:\n    Pasteur                                     64.309\n    Grant-White                                 51.542\n\nModel Test Baseline Model:\n\n  Test statistic                               957.769\n  Degrees of freedom                                72\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.923\n  Tucker-Lewis Index (TLI)                       0.885\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -3682.198\n  Loglikelihood unrestricted model (H1)      -3624.272\n                                                      \n  Akaike (AIC)                                7484.395\n  Bayesian (BIC)                              7706.822\n  Sample-size adjusted Bayesian (SABIC)       7516.536\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.097\n  90 Percent confidence interval - lower         0.075\n  90 Percent confidence interval - upper         0.120\n  P-value H_0: RMSEA <= 0.050                    0.001\n  P-value H_0: RMSEA >= 0.080                    0.897\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.068\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\n\nGroup 1 [Pasteur]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  visual =~                                           \n    x1                1.000                           \n    x2                0.394    0.122    3.220    0.001\n    x3                0.570    0.140    4.076    0.000\n  textual =~                                          \n    x4                1.000                           \n    x5                1.183    0.102   11.613    0.000\n    x6                0.875    0.077   11.421    0.000\n  speed =~                                            \n    x7                1.000                           \n    x8                1.125    0.277    4.057    0.000\n    x9                0.922    0.225    4.104    0.000\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  visual ~~                                           \n    textual           0.479    0.106    4.531    0.000\n    speed             0.185    0.077    2.397    0.017\n  textual ~~                                          \n    speed             0.182    0.069    2.628    0.009\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)\n   .x1                4.941    0.095   52.249    0.000\n   .x2                5.984    0.098   60.949    0.000\n   .x3                2.487    0.093   26.778    0.000\n   .x4                2.823    0.092   30.689    0.000\n   .x5                3.995    0.105   38.183    0.000\n   .x6                1.922    0.079   24.321    0.000\n   .x7                4.432    0.087   51.181    0.000\n   .x8                5.563    0.078   71.214    0.000\n   .x9                5.418    0.079   68.440    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n   .x1                0.298    0.232    1.286    0.198\n   .x2                1.334    0.158    8.464    0.000\n   .x3                0.989    0.136    7.271    0.000\n   .x4                0.425    0.069    6.138    0.000\n   .x5                0.456    0.086    5.292    0.000\n   .x6                0.290    0.050    5.780    0.000\n   .x7                0.820    0.125    6.580    0.000\n   .x8                0.510    0.116    4.406    0.000\n   .x9                0.680    0.104    6.516    0.000\n    visual            1.097    0.276    3.967    0.000\n    textual           0.894    0.150    5.963    0.000\n    speed             0.350    0.126    2.778    0.005\n\n\nGroup 2 [Grant-White]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  visual =~                                           \n    x1                1.000                           \n    x2                0.736    0.155    4.760    0.000\n    x3                0.925    0.166    5.583    0.000\n  textual =~                                          \n    x4                1.000                           \n    x5                0.990    0.087   11.418    0.000\n    x6                0.963    0.085   11.377    0.000\n  speed =~                                            \n    x7                1.000                           \n    x8                1.226    0.187    6.569    0.000\n    x9                1.058    0.165    6.429    0.000\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  visual ~~                                           \n    textual           0.408    0.098    4.153    0.000\n    speed             0.276    0.076    3.639    0.000\n  textual ~~                                          \n    speed             0.222    0.073    3.022    0.003\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)\n   .x1                4.930    0.095   51.696    0.000\n   .x2                6.200    0.092   67.416    0.000\n   .x3                1.996    0.086   23.195    0.000\n   .x4                3.317    0.093   35.625    0.000\n   .x5                4.712    0.096   48.986    0.000\n   .x6                2.469    0.094   26.277    0.000\n   .x7                3.921    0.086   45.819    0.000\n   .x8                5.488    0.087   63.174    0.000\n   .x9                5.327    0.085   62.571    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n   .x1                0.715    0.126    5.676    0.000\n   .x2                0.899    0.123    7.339    0.000\n   .x3                0.557    0.103    5.409    0.000\n   .x4                0.315    0.065    4.870    0.000\n   .x5                0.419    0.072    5.812    0.000\n   .x6                0.406    0.069    5.880    0.000\n   .x7                0.600    0.091    6.584    0.000\n   .x8                0.401    0.094    4.249    0.000\n   .x9                0.535    0.089    6.010    0.000\n    visual            0.604    0.160    3.762    0.000\n    textual           0.942    0.152    6.177    0.000\n    speed             0.461    0.118    3.910    0.000\n```\n\n\n:::\n:::\n\n\nThe **configural invariance** model provides a baseline for comparing the factor structure across groups (schools: **Pasteur** and **Grant-White**).\n\n-   **Fit Indices**:\n\n    -   The **CFI** of 0.923 and **TLI** of 0.885 suggest a reasonably good fit but not excellent.\n\n    -   The **RMSEA** of 0.097 is slightly below the recommended 0.10 threshold.\n\n    -   The **SRMR** of 0.068 is within an acceptable range, below 0.10, indicating a good fit.\n\nThese results show that the overall factor structure is consistent across the two schools, but there's room for improvement in model fit.\n\n### 3.2. Metric Invariance\n\nNext, we would proceed to test **metric invariance**, where we constrain the factor loadings across groups to assess if the model behaves equivalently in both schools.\n\n\n::: {.cell code_folding='true' filename=''}\n\n```{.r .cell-code  code-fold=\"true\"}\nfit_metric <- cfa(HS.model, data = HolzingerSwineford1939, group = \"school\", group.equal = \"loadings\")\nsummary(fit_metric, fit.measures = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nlavaan 0.6-19 ended normally after 42 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        60\n  Number of equality constraints                     6\n\n  Number of observations per group:                   \n    Pasteur                                        156\n    Grant-White                                    145\n\nModel Test User Model:\n                                                      \n  Test statistic                               124.044\n  Degrees of freedom                                54\n  P-value (Chi-square)                           0.000\n  Test statistic for each group:\n    Pasteur                                     68.825\n    Grant-White                                 55.219\n\nModel Test Baseline Model:\n\n  Test statistic                               957.769\n  Degrees of freedom                                72\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.921\n  Tucker-Lewis Index (TLI)                       0.895\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -3686.294\n  Loglikelihood unrestricted model (H1)      -3624.272\n                                                      \n  Akaike (AIC)                                7480.587\n  Bayesian (BIC)                              7680.771\n  Sample-size adjusted Bayesian (SABIC)       7509.514\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.093\n  90 Percent confidence interval - lower         0.071\n  90 Percent confidence interval - upper         0.114\n  P-value H_0: RMSEA <= 0.050                    0.001\n  P-value H_0: RMSEA >= 0.080                    0.845\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.072\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\n\nGroup 1 [Pasteur]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  visual =~                                           \n    x1                1.000                           \n    x2      (.p2.)    0.599    0.100    5.979    0.000\n    x3      (.p3.)    0.784    0.108    7.267    0.000\n  textual =~                                          \n    x4                1.000                           \n    x5      (.p5.)    1.083    0.067   16.049    0.000\n    x6      (.p6.)    0.912    0.058   15.785    0.000\n  speed =~                                            \n    x7                1.000                           \n    x8      (.p8.)    1.201    0.155    7.738    0.000\n    x9      (.p9.)    1.038    0.136    7.629    0.000\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  visual ~~                                           \n    textual           0.416    0.097    4.271    0.000\n    speed             0.169    0.064    2.643    0.008\n  textual ~~                                          \n    speed             0.176    0.061    2.882    0.004\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)\n   .x1                4.941    0.093   52.991    0.000\n   .x2                5.984    0.100   60.096    0.000\n   .x3                2.487    0.094   26.465    0.000\n   .x4                2.823    0.093   30.371    0.000\n   .x5                3.995    0.101   39.714    0.000\n   .x6                1.922    0.081   23.711    0.000\n   .x7                4.432    0.086   51.540    0.000\n   .x8                5.563    0.078   71.087    0.000\n   .x9                5.418    0.079   68.153    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n   .x1                0.551    0.137    4.010    0.000\n   .x2                1.258    0.155    8.117    0.000\n   .x3                0.882    0.128    6.884    0.000\n   .x4                0.434    0.070    6.238    0.000\n   .x5                0.508    0.082    6.229    0.000\n   .x6                0.266    0.050    5.294    0.000\n   .x7                0.849    0.114    7.468    0.000\n   .x8                0.515    0.095    5.409    0.000\n   .x9                0.658    0.096    6.865    0.000\n    visual            0.805    0.171    4.714    0.000\n    textual           0.913    0.137    6.651    0.000\n    speed             0.305    0.078    3.920    0.000\n\n\nGroup 2 [Grant-White]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  visual =~                                           \n    x1                1.000                           \n    x2      (.p2.)    0.599    0.100    5.979    0.000\n    x3      (.p3.)    0.784    0.108    7.267    0.000\n  textual =~                                          \n    x4                1.000                           \n    x5      (.p5.)    1.083    0.067   16.049    0.000\n    x6      (.p6.)    0.912    0.058   15.785    0.000\n  speed =~                                            \n    x7                1.000                           \n    x8      (.p8.)    1.201    0.155    7.738    0.000\n    x9      (.p9.)    1.038    0.136    7.629    0.000\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  visual ~~                                           \n    textual           0.437    0.099    4.423    0.000\n    speed             0.314    0.079    3.958    0.000\n  textual ~~                                          \n    speed             0.226    0.072    3.144    0.002\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)\n   .x1                4.930    0.097   50.763    0.000\n   .x2                6.200    0.091   68.379    0.000\n   .x3                1.996    0.085   23.455    0.000\n   .x4                3.317    0.092   35.950    0.000\n   .x5                4.712    0.100   47.173    0.000\n   .x6                2.469    0.091   27.248    0.000\n   .x7                3.921    0.086   45.555    0.000\n   .x8                5.488    0.087   63.257    0.000\n   .x9                5.327    0.085   62.786    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n   .x1                0.645    0.127    5.084    0.000\n   .x2                0.933    0.121    7.732    0.000\n   .x3                0.605    0.096    6.282    0.000\n   .x4                0.329    0.062    5.279    0.000\n   .x5                0.384    0.073    5.270    0.000\n   .x6                0.437    0.067    6.576    0.000\n   .x7                0.599    0.090    6.651    0.000\n   .x8                0.406    0.089    4.541    0.000\n   .x9                0.532    0.086    6.202    0.000\n    visual            0.722    0.161    4.490    0.000\n    textual           0.906    0.136    6.646    0.000\n    speed             0.475    0.109    4.347    0.000\n```\n\n\n:::\n:::\n\n\n-   **CFI** (0.921) and **TLI** (0.895) are still relatively good, indicating that the constrained model is acceptable.\n\n-   **RMSEA** (0.093) suggests an acceptable fit.\n\n-   **SRMR** (0.072) is still below 0.08, indicating acceptable fit.\n\nThe comparison between the configural and metric models shows a slight decline in fit, but the invariance model still seems reasonably supported. This indicates that the factor loadings are equivalent across the two schools, allowing us to meaningfully compare relationships between items and latent factors.\n\n### 3.3. Scalar Invariance\n\nNext, we would proceed with testing **scalar invariance**.\n\n\n::: {.cell code_folding='true' filename=''}\n\n```{.r .cell-code  code-fold=\"true\"}\nfit_scalar <- cfa(HS.model, data = HolzingerSwineford1939, group = \"school\", group.equal = c(\"loadings\", \"intercepts\"))\nsummary(fit_scalar, fit.measures = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nlavaan 0.6-19 ended normally after 60 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        63\n  Number of equality constraints                    15\n\n  Number of observations per group:                   \n    Pasteur                                        156\n    Grant-White                                    145\n\nModel Test User Model:\n                                                      \n  Test statistic                               164.103\n  Degrees of freedom                                60\n  P-value (Chi-square)                           0.000\n  Test statistic for each group:\n    Pasteur                                     90.210\n    Grant-White                                 73.892\n\nModel Test Baseline Model:\n\n  Test statistic                               957.769\n  Degrees of freedom                                72\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.882\n  Tucker-Lewis Index (TLI)                       0.859\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -3706.323\n  Loglikelihood unrestricted model (H1)      -3624.272\n                                                      \n  Akaike (AIC)                                7508.647\n  Bayesian (BIC)                              7686.588\n  Sample-size adjusted Bayesian (SABIC)       7534.359\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.107\n  90 Percent confidence interval - lower         0.088\n  90 Percent confidence interval - upper         0.127\n  P-value H_0: RMSEA <= 0.050                    0.000\n  P-value H_0: RMSEA >= 0.080                    0.989\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.082\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\n\nGroup 1 [Pasteur]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  visual =~                                           \n    x1                1.000                           \n    x2      (.p2.)    0.576    0.101    5.713    0.000\n    x3      (.p3.)    0.798    0.112    7.146    0.000\n  textual =~                                          \n    x4                1.000                           \n    x5      (.p5.)    1.120    0.066   16.965    0.000\n    x6      (.p6.)    0.932    0.056   16.608    0.000\n  speed =~                                            \n    x7                1.000                           \n    x8      (.p8.)    1.130    0.145    7.786    0.000\n    x9      (.p9.)    1.009    0.132    7.667    0.000\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  visual ~~                                           \n    textual           0.410    0.095    4.293    0.000\n    speed             0.178    0.066    2.687    0.007\n  textual ~~                                          \n    speed             0.180    0.062    2.900    0.004\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)\n   .x1      (.25.)    5.001    0.090   55.760    0.000\n   .x2      (.26.)    6.151    0.077   79.905    0.000\n   .x3      (.27.)    2.271    0.083   27.387    0.000\n   .x4      (.28.)    2.778    0.087   31.953    0.000\n   .x5      (.29.)    4.035    0.096   41.858    0.000\n   .x6      (.30.)    1.926    0.079   24.426    0.000\n   .x7      (.31.)    4.242    0.073   57.975    0.000\n   .x8      (.32.)    5.630    0.072   78.531    0.000\n   .x9      (.33.)    5.465    0.069   79.016    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n   .x1                0.555    0.139    3.983    0.000\n   .x2                1.296    0.158    8.186    0.000\n   .x3                0.944    0.136    6.929    0.000\n   .x4                0.445    0.069    6.430    0.000\n   .x5                0.502    0.082    6.136    0.000\n   .x6                0.263    0.050    5.264    0.000\n   .x7                0.888    0.120    7.416    0.000\n   .x8                0.541    0.095    5.706    0.000\n   .x9                0.654    0.096    6.805    0.000\n    visual            0.796    0.172    4.641    0.000\n    textual           0.879    0.131    6.694    0.000\n    speed             0.322    0.082    3.914    0.000\n\n\nGroup 2 [Grant-White]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  visual =~                                           \n    x1                1.000                           \n    x2      (.p2.)    0.576    0.101    5.713    0.000\n    x3      (.p3.)    0.798    0.112    7.146    0.000\n  textual =~                                          \n    x4                1.000                           \n    x5      (.p5.)    1.120    0.066   16.965    0.000\n    x6      (.p6.)    0.932    0.056   16.608    0.000\n  speed =~                                            \n    x7                1.000                           \n    x8      (.p8.)    1.130    0.145    7.786    0.000\n    x9      (.p9.)    1.009    0.132    7.667    0.000\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  visual ~~                                           \n    textual           0.427    0.097    4.417    0.000\n    speed             0.329    0.082    4.006    0.000\n  textual ~~                                          \n    speed             0.236    0.073    3.224    0.001\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)\n   .x1      (.25.)    5.001    0.090   55.760    0.000\n   .x2      (.26.)    6.151    0.077   79.905    0.000\n   .x3      (.27.)    2.271    0.083   27.387    0.000\n   .x4      (.28.)    2.778    0.087   31.953    0.000\n   .x5      (.29.)    4.035    0.096   41.858    0.000\n   .x6      (.30.)    1.926    0.079   24.426    0.000\n   .x7      (.31.)    4.242    0.073   57.975    0.000\n   .x8      (.32.)    5.630    0.072   78.531    0.000\n   .x9      (.33.)    5.465    0.069   79.016    0.000\n    visual           -0.148    0.122   -1.211    0.226\n    textual           0.576    0.117    4.918    0.000\n    speed            -0.177    0.090   -1.968    0.049\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n   .x1                0.654    0.128    5.094    0.000\n   .x2                0.964    0.123    7.812    0.000\n   .x3                0.641    0.101    6.316    0.000\n   .x4                0.343    0.062    5.534    0.000\n   .x5                0.376    0.073    5.133    0.000\n   .x6                0.437    0.067    6.559    0.000\n   .x7                0.625    0.095    6.574    0.000\n   .x8                0.434    0.088    4.914    0.000\n   .x9                0.522    0.086    6.102    0.000\n    visual            0.708    0.160    4.417    0.000\n    textual           0.870    0.131    6.659    0.000\n    speed             0.505    0.115    4.379    0.000\n```\n\n\n:::\n:::\n\n\nThe **scalar invariance** model (which adds constraints on intercepts) shows the following:\n\n-   **Fit indices**: The **CFI** has dropped to 0.882 and **TLI** to 0.859, indicating a lower fit compared to the metric model. **RMSEA** increased to 0.107, which exceeds the acceptable threshold (0.10), suggesting a less satisfactory fit.\n\n-   **SRMR** is now 0.082.\n\nOverall, the model fit deteriorates, indicating that the intercepts might not be fully invariant across the two groups.\n\n### 3.4. Strict Invariance\n\nFinally lets test the **strict invariance**.\n\n\n::: {.cell code_folding='true' filename=''}\n\n```{.r .cell-code  code-fold=\"true\"}\nfit_strict <- cfa(HS.model, data = HolzingerSwineford1939, group = \"school\", group.equal = c(\"loadings\", \"intercepts\", \"residuals\"))\nsummary(fit_strict, fit.measures = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nlavaan 0.6-19 ended normally after 59 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        63\n  Number of equality constraints                    24\n\n  Number of observations per group:                   \n    Pasteur                                        156\n    Grant-White                                    145\n\nModel Test User Model:\n                                                      \n  Test statistic                               181.511\n  Degrees of freedom                                69\n  P-value (Chi-square)                           0.000\n  Test statistic for each group:\n    Pasteur                                     93.093\n    Grant-White                                 88.419\n\nModel Test Baseline Model:\n\n  Test statistic                               957.769\n  Degrees of freedom                                72\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.873\n  Tucker-Lewis Index (TLI)                       0.867\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -3715.028\n  Loglikelihood unrestricted model (H1)      -3624.272\n                                                      \n  Akaike (AIC)                                7508.055\n  Bayesian (BIC)                              7652.632\n  Sample-size adjusted Bayesian (SABIC)       7528.947\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.104\n  90 Percent confidence interval - lower         0.086\n  90 Percent confidence interval - upper         0.123\n  P-value H_0: RMSEA <= 0.050                    0.000\n  P-value H_0: RMSEA >= 0.080                    0.984\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.088\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\n\nGroup 1 [Pasteur]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  visual =~                                           \n    x1                1.000                           \n    x2      (.p2.)    0.591    0.104    5.691    0.000\n    x3      (.p3.)    0.837    0.116    7.182    0.000\n  textual =~                                          \n    x4                1.000                           \n    x5      (.p5.)    1.125    0.066   17.134    0.000\n    x6      (.p6.)    0.933    0.056   16.752    0.000\n  speed =~                                            \n    x7                1.000                           \n    x8      (.p8.)    1.121    0.151    7.424    0.000\n    x9      (.p9.)    1.028    0.140    7.356    0.000\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  visual ~~                                           \n    textual           0.367    0.094    3.915    0.000\n    speed             0.174    0.065    2.666    0.008\n  textual ~~                                          \n    speed             0.176    0.062    2.827    0.005\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)\n   .x1      (.25.)    5.012    0.090   55.461    0.000\n   .x2      (.26.)    6.133    0.077   79.814    0.000\n   .x3      (.27.)    2.314    0.083   28.037    0.000\n   .x4      (.28.)    2.784    0.086   32.193    0.000\n   .x5      (.29.)    4.029    0.096   41.812    0.000\n   .x6      (.30.)    1.927    0.081   23.747    0.000\n   .x7      (.31.)    4.271    0.073   58.428    0.000\n   .x8      (.32.)    5.622    0.072   78.502    0.000\n   .x9      (.33.)    5.461    0.070   78.438    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n   .x1      (.10.)    0.638    0.102    6.249    0.000\n   .x2      (.11.)    1.130    0.102   11.124    0.000\n   .x3      (.12.)    0.771    0.090    8.608    0.000\n   .x4      (.13.)    0.383    0.047    8.095    0.000\n   .x5      (.14.)    0.435    0.057    7.616    0.000\n   .x6      (.15.)    0.354    0.042    8.341    0.000\n   .x7      (.16.)    0.769    0.080    9.571    0.000\n   .x8      (.17.)    0.501    0.071    7.021    0.000\n   .x9      (.18.)    0.576    0.069    8.353    0.000\n    visual            0.767    0.164    4.686    0.000\n    textual           0.894    0.131    6.827    0.000\n    speed             0.340    0.085    4.016    0.000\n\n\nGroup 2 [Grant-White]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  visual =~                                           \n    x1                1.000                           \n    x2      (.p2.)    0.591    0.104    5.691    0.000\n    x3      (.p3.)    0.837    0.116    7.182    0.000\n  textual =~                                          \n    x4                1.000                           \n    x5      (.p5.)    1.125    0.066   17.134    0.000\n    x6      (.p6.)    0.933    0.056   16.752    0.000\n  speed =~                                            \n    x7                1.000                           \n    x8      (.p8.)    1.121    0.151    7.424    0.000\n    x9      (.p9.)    1.028    0.140    7.356    0.000\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  visual ~~                                           \n    textual           0.422    0.095    4.446    0.000\n    speed             0.331    0.081    4.069    0.000\n  textual ~~                                          \n    speed             0.236    0.074    3.194    0.001\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)\n   .x1      (.25.)    5.012    0.090   55.461    0.000\n   .x2      (.26.)    6.133    0.077   79.814    0.000\n   .x3      (.27.)    2.314    0.083   28.037    0.000\n   .x4      (.28.)    2.784    0.086   32.193    0.000\n   .x5      (.29.)    4.029    0.096   41.812    0.000\n   .x6      (.30.)    1.927    0.081   23.747    0.000\n   .x7      (.31.)    4.271    0.073   58.428    0.000\n   .x8      (.32.)    5.622    0.072   78.502    0.000\n   .x9      (.33.)    5.461    0.070   78.438    0.000\n    visual           -0.157    0.120   -1.316    0.188\n    textual           0.575    0.118    4.888    0.000\n    speed            -0.176    0.090   -1.958    0.050\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n   .x1      (.10.)    0.638    0.102    6.249    0.000\n   .x2      (.11.)    1.130    0.102   11.124    0.000\n   .x3      (.12.)    0.771    0.090    8.608    0.000\n   .x4      (.13.)    0.383    0.047    8.095    0.000\n   .x5      (.14.)    0.435    0.057    7.616    0.000\n   .x6      (.15.)    0.354    0.042    8.341    0.000\n   .x7      (.16.)    0.769    0.080    9.571    0.000\n   .x8      (.17.)    0.501    0.071    7.021    0.000\n   .x9      (.18.)    0.576    0.069    8.353    0.000\n    visual            0.657    0.150    4.379    0.000\n    textual           0.876    0.132    6.621    0.000\n    speed             0.478    0.116    4.138    0.000\n```\n\n\n:::\n:::\n\n\n**Fit Statistics:**\n\n-   **Chi-square (181.511, df = 69, p \\< 0.001):** Significant, indicating that strict invariance does not hold perfectly, but Chi-square is sensitive to large sample sizes.\n\n-   **CFI (0.873) and TLI (0.867):** Both are below 0.90, indicating a moderate fit. These indices suggest some misfit when imposing strict invariance.\n\n-   **RMSEA (0.104):** Exceeds the desired threshold of 0.10, suggesting that the model fit could be improved.\n\n-   **SRMR (0.088):** Slightly below the 0.10 threshold.\n\nStrict invariance constrains residuals to be equal across groups. Although the fit is not ideal, it is common for strict invariance to show worse fit compared to less restrictive models.\n\n## 4. Evaluation\n\nWe can all four models with anova() function:\\\n\n\n::: {.cell code_folding='true' filename=''}\n\n```{.r .cell-code  code-fold=\"true\"}\nanova(fit_configural, fit_metric, fit_scalar, fit_strict)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nChi-Squared Difference Test\n\n               Df    AIC    BIC  Chisq Chisq diff    RMSEA Df diff Pr(>Chisq)\nfit_configural 48 7484.4 7706.8 115.85                                       \nfit_metric     54 7480.6 7680.8 124.04      8.192 0.049272       6    0.22436\nfit_scalar     60 7508.6 7686.6 164.10     40.059 0.194211       6  4.435e-07\nfit_strict     69 7508.1 7652.6 181.51     17.409 0.078790       9    0.04269\n                  \nfit_configural    \nfit_metric        \nfit_scalar     ***\nfit_strict     *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n1.  **Configural Model**: This is the baseline with good fit (Chisq = 115.85).\n\n2.  **Metric Model**: No significant difference from the configural model (p = 0.224), suggesting factor loadings are invariant across groups.\n\n3.  **Scalar Model**: Significant difference (p \\< 0.001), implying that intercepts are not invariant across groups, indicating a potential bias.\n\n4.  **Strict Model**: Marginally significant difference (p = 0.043), suggesting that residual variances also vary, reducing strict invariance.\n\nOverall, the scalar and strict invariance do not hold as strongly as the other two.\n\nLet's investigate all models in a chart and see how the model fit metrics deteriorates after each checkpoint.\n\n\n::: {.cell code_folding='true' filename=''}\n\n```{.r .cell-code  code-fold=\"true\"}\nfitMeasures_df <- data.frame(\n  Model = c(\"Configural\", \"Metric\", \"Scalar\", \"Strict\"),\n  CFI = c(0.923, 0.921, 0.882, 0.873),\n  RMSEA = c(0.097, 0.093, 0.107, 0.104),\n  SRMR = c(0.068, 0.072, 0.082, 0.088)\n)\n# Plot with thresholds and legends\nggplot(fitMeasures_df, aes(x = Model)) +\n  geom_point(aes(y = CFI, color = \"CFI\"), size = 4) +\n  geom_point(aes(y = RMSEA, color = \"RMSEA\"), size = 4) +\n  geom_point(aes(y = SRMR, color = \"SRMR\"), size = 4) +\n  geom_line(aes(y = CFI, group = 1, color = \"CFI\")) +\n  geom_line(aes(y = RMSEA, group = 1, color = \"RMSEA\")) +\n  geom_line(aes(y = SRMR, group = 1, color = \"SRMR\")) +\n  \n  # Add threshold lines\n  geom_hline(yintercept = 0.90, linetype = \"dashed\", color = \"blue\", size = 0.5) +  # CFI threshold\n  geom_hline(yintercept = 0.10, linetype = \"dashed\", color = \"tomato\", size = 0.5) +   # RMSEA & SRMR threshold\n  \n  # Manual legend for threshold lines\n  annotate(\"text\", x = 4.5, y = 0.91, label = \"0.90\", color = \"blue\", size = 3.5, hjust = 1) +\n  annotate(\"text\", x = 4.5, y = 0.09, label = \"0.10\", color = \"tomato\", size = 3.5, hjust = 1) +\n  \n  labs(y = \"Fit Measures\", x = \"Model Type\", color = \"Fit Index\",\n       title = \"Comparison of Fit Measures Across Invariance Models with Thresholds\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\nAs you see, configural and metric invariance is fulfilled as their CFI levels are above 0.90, and RMSEA & SRMR are below 0.10. Yet, scalar and strict invariance is slightly above the thresholds for RMSEA and SRMR and below for CFI.\n\nThese findings suggest some modifications might be a good idea on scalar and strict invariance models. Yet, model modifications are another blog post's issue.\n\n## 5. Conclusion\n\nIn this blog post, we explored the concept of measurement invariance and its importance in ensuring that a test measures the same construct across different sub-groups of the population. Using the lavaan package in R, we conducted a series of tests to assess different levels of MI — configural, metric, scalar, and strict invariance — on the Holzinger and Swineford dataset.\n\n## 6. Further Analysis\n\nAs scalar and strict invariance is not completely fulfilled, modifications might be usefull on the model for better fit.\n\nWe have run an analysis on school variable. Measurement invariance can also be checked using the gender variable.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}